{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbKsGV5bnR7P"
      },
      "source": [
        "###Algoritmos ICA-PE\n",
        "*   Algoritmo entrenado y confiable KNN (K-Nearest Neighbors) que demuestre el\n",
        "accuracy del código de clasificación ICA-PE inicial.\n",
        "\n",
        "* Algoritmo entrenado y confiable Random Forest que demuestre el accuracy del\n",
        "código de clasificación ICA-PE inicial.\n",
        "* Algoritmo entrenado y confiable SVM (Support Vector Machine) que demuestre el\n",
        "accuracy del código de clasificación ICA-PE inicial.\n",
        "* Algoritmo para el cálculo del IC-PE basado en las fórmulas de la documentación\n",
        "dadas por el CLIENTE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHXsWHYknR7P"
      },
      "source": [
        "\n",
        "\n",
        "#Inicio del proyecto: 21 de julio del 2024.\n",
        "* Primera revisión: 27 de julio del 2024.\n",
        "* Segunda revisión: 3 de agosto del 2024.\n",
        "* Tercera revisión: 10 de agosto del 2024.\n",
        "* Entrega final: 17 de agosto del 2024.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55SjYUfRMphb"
      },
      "source": [
        "#Importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xdtz2MIVMrv8"
      },
      "outputs": [],
      "source": [
        "#Importaciones\n",
        "import os\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Union, Callable, TypeVar, Type\n",
        "import math\n",
        "from abc import ABC, abstractmethod\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from collections import Counter\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install openpyxl"
      ],
      "metadata": {
        "id": "ELoDdiozoxfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF0ji3Mh9N4q"
      },
      "source": [
        "# Estados iniciales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35lQHWCMMDoA"
      },
      "source": [
        "## Estados iniciales Clase Eca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVJdjQxcMfEv"
      },
      "outputs": [],
      "source": [
        "Operation = Callable[[float, float], bool]\n",
        "\n",
        "EcaType = TypeVar('EcaType', bound='Eca')\n",
        "\n",
        "compare_operations : Dict[str,Operation ] = {\n",
        "  'greater_than': lambda x, y: x > y,\n",
        "  'less_than': lambda x, y: x < y,\n",
        "  'equal_to': lambda x, y: x == y,\n",
        "  'greater_or_equal': lambda x, y: x >= y,\n",
        "  'less_or_equal': lambda x, y: x <= y\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbIOx2IYM0Qu"
      },
      "source": [
        "## Estados iniciales Clase Category1A2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGKbLcT8M5ds"
      },
      "outputs": [],
      "source": [
        "catgory1A2Propertynumber = 13\n",
        "\n",
        "category1A2Nominals: Dict[str, Union[float, int]] = {\n",
        "      'O': 5.0,\n",
        "      'DBO': 5.0,\n",
        "      'AS_': 0.01,\n",
        "      'CD': 0.005,\n",
        "      'CU': 2.0,\n",
        "      'CR': 0.05,\n",
        "      'FE': 1.0,\n",
        "      'MN': 0.4,\n",
        "      'PB': 0.05,\n",
        "      'HG': 0.002,\n",
        "      'ZN': 5.0,\n",
        "      'MIN_PH': 5.5,\n",
        "      'MAX_PH': 9.0,\n",
        "      'MAX_NMP_COLIFORMES': 2000\n",
        "}\n",
        "\n",
        "category1A2HeadersA: List[Dict[str,str]] = [\n",
        "    {\n",
        "      'key' : '_dbo',\n",
        "      'label' : 'dbo'\n",
        "    },\n",
        "    {\n",
        "      'key' : '_mn',\n",
        "      'label' : 'mn'\n",
        "    },\n",
        "    {\n",
        "      'key' : '_zn',\n",
        "      'label' : 'zn'\n",
        "    },\n",
        "    {\n",
        "      'key' : '_coliformes',\n",
        "      'label' : 'coliformes'\n",
        "    },\n",
        "]\n",
        "\n",
        "category1A2HeadersB: List[Dict[str,str]] = [\n",
        "    {\n",
        "      'key' : '_o',\n",
        "      'label' : 'o'\n",
        "    },\n",
        "    {\n",
        "      'key' : '_fe',\n",
        "      'label' : 'fe'\n",
        "    },\n",
        "    {\n",
        "      'key' : '_ph',\n",
        "      'label' : 'ph'\n",
        "    },\n",
        "    {\n",
        "      'key' : '_cu',\n",
        "      'label' : 'cu'\n",
        "    },\n",
        "]\n",
        "\n",
        "category1A2HeadersC: List[Dict[str,str]] = [\n",
        "    {\n",
        "      'key' : '_as_',\n",
        "      'label' : 'as'\n",
        "    },\n",
        "    {\n",
        "      'key' : '_cd',\n",
        "      'label' : 'cd'\n",
        "    },\n",
        "    {\n",
        "      'key' : '_pb',\n",
        "      'label' : 'pb'\n",
        "    },\n",
        "]\n",
        "\n",
        "category1A2HeadersD: List[Dict[str,str]] = [\n",
        "    {\n",
        "      'key' : '_cr',\n",
        "      'label' : 'cr'\n",
        "    },\n",
        "    {\n",
        "      'key' : '_hg',\n",
        "      'label' : 'hg'\n",
        "    }\n",
        "]\n",
        "\n",
        "category1A2Probes: List[Dict[str, Union[float, int]]] = [\n",
        "   {\n",
        "     'ATRIBUTE' : '_o',\n",
        "     'NOMINAL' : 'O',\n",
        "     'OPERATION': 'greater_or_equal',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_dbo',\n",
        "     'NOMINAL' : 'DBO',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_as_',\n",
        "     'NOMINAL' : 'AS_',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_cd',\n",
        "     'NOMINAL' : 'CD',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_cu',\n",
        "     'NOMINAL' : 'CU',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_cr',\n",
        "     'NOMINAL' : 'CR',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_fe',\n",
        "     'NOMINAL' : 'FE',\n",
        "     'OPERATION': 'less_than'\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_mn',\n",
        "     'NOMINAL' : 'MN',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_pb',\n",
        "     'NOMINAL' : 'PB',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_hg',\n",
        "     'NOMINAL' : 'HG',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_zn',\n",
        "     'NOMINAL' : 'ZN',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_ph',\n",
        "     'NOMINAL' : 'MIN_PH',\n",
        "     'OPERATION': 'greater_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_ph',\n",
        "     'NOMINAL' : 'MAX_PH',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_coliformes',\n",
        "     'NOMINAL' : 'MAX_NMP_COLIFORMES',\n",
        "     'OPERATION': 'less_than',\n",
        "   }\n",
        " ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XySz21EvTQj5"
      },
      "source": [
        "##Estados iniciales Clase Category3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orCtL3U_Tbfl"
      },
      "outputs": [],
      "source": [
        "Category3Type = TypeVar('Category3Type', bound='Category3')\n",
        "\n",
        "category3Propertynumber = 17\n",
        "\n",
        "restrictedIrrigationNominals: Dict[str, Union[float, int]] = {\n",
        "      'CLORUROS': 500,\n",
        "      'CONDUCTIVIDAD': 2500,\n",
        "      'DBO': 15,\n",
        "      'O': 4.0,\n",
        "      'AL':5.0,\n",
        "      'AS_': 0.1,\n",
        "      'B': 1.0,\n",
        "      'CD': 0.01,\n",
        "      'CU': 0.2,\n",
        "      'FE': 5.0,\n",
        "      'MN': 0.2,\n",
        "      'HG': 0.001,\n",
        "      'PB': 0.05,\n",
        "      'ZN': 2.0,\n",
        "      'MIN_PH': 6.5,\n",
        "      'MAX_PH': 8.5,\n",
        "      'MAX_NMP_COLIFORMES': 2000,\n",
        "      'MAX_HUEVOS_DE_EMINTOS' : 1\n",
        "}\n",
        "\n",
        "noRestrictedIrrigationNominals: Dict[str, Union[float, int]] = {\n",
        "      'CLORUROS': 500,\n",
        "      'CONDUCTIVIDAD': 2500,\n",
        "      'DBO': 15,\n",
        "      'O': 4.0,\n",
        "      'AL':5.0,\n",
        "      'AS_': 0.1,\n",
        "      'B': 1.0,\n",
        "      'CD': 0.01,\n",
        "      'CU': 0.2,\n",
        "      'FE': 5.0,\n",
        "      'MN': 0.2,\n",
        "      'HG': 0.001,\n",
        "      'PB': 0.05,\n",
        "      'ZN': 2.0,\n",
        "      'MIN_PH': 6.5,\n",
        "      'MAX_PH': 8.5,\n",
        "      'MAX_NMP_COLIFORMES': 1000,\n",
        "      'MAX_HUEVOS_DE_EMINTOS' : 1\n",
        "}\n",
        "\n",
        "animalDrinkingWaterNominals: Dict[str, Union[float, int]] = {\n",
        "      'CONDUCTIVIDAD': 2500,\n",
        "      'DBO': 15,\n",
        "      'O': 5.0,\n",
        "      'AL':5.0,\n",
        "      'AS_': 0.2,\n",
        "      'B': 5.0,\n",
        "      'CD': 0.05,\n",
        "      'CU': 0.05,\n",
        "      'MN': 0.2,\n",
        "      'HG': 0.01,\n",
        "      'PB': 0.05,\n",
        "      'ZN': 24.0,\n",
        "      'MIN_PH': 6.5,\n",
        "      'MAX_PH': 8.4,\n",
        "      'MAX_NMP_COLIFORMES': 1000\n",
        "}\n",
        "\n",
        "\n",
        "category3HeadersA: List[Dict[str,str]] = [\n",
        "    {\n",
        "      'key': '_conductividad',\n",
        "      'label':  'conductividad'\n",
        "    },\n",
        "    {\n",
        "      'key': '_coliformes',\n",
        "      'label':  'coliformes'\n",
        "    },\n",
        "    {\n",
        "      'key': '_al',\n",
        "      'label':  'al'\n",
        "    },\n",
        "]\n",
        "\n",
        "category3HeadersB: List[Dict[str,str]] = [\n",
        "    # {\n",
        "    #   'key': '_cloruros',\n",
        "    #   'label':  'cloruros'\n",
        "    # },\n",
        "    {\n",
        "      'key': '_dbo',\n",
        "      'label':  'dbo'\n",
        "    },\n",
        "    # {\n",
        "    #   'key': '_fe',\n",
        "    #   'label':  'fe'\n",
        "    # },\n",
        "    {\n",
        "      'key': '_mn',\n",
        "      'label':  'mn'\n",
        "    },\n",
        "    {\n",
        "      'key': '_zn',\n",
        "      'label':  'zn'\n",
        "    },\n",
        "]\n",
        "\n",
        "category3HeadersC: List[Dict[str,str]] = [\n",
        "    {\n",
        "      'key': '_ph',\n",
        "      'label':  'ph'\n",
        "    },\n",
        "    {\n",
        "      'key': '_o',\n",
        "      'label':  'o'\n",
        "    },\n",
        "    {\n",
        "      'key': '_cu',\n",
        "      'label':  'cu'\n",
        "    }\n",
        "]\n",
        "\n",
        "category3HeadersD: List[Dict[str,str]] = [\n",
        "    {\n",
        "      'key': '_as_',\n",
        "      'label':  'as'\n",
        "    },\n",
        "    {\n",
        "      'key': '_b',\n",
        "      'label':  'b'\n",
        "    },\n",
        "    {\n",
        "      'key': '_cd',\n",
        "      'label':  'cd'\n",
        "    },\n",
        "    {\n",
        "      'key': '_hg',\n",
        "      'label':  'hg'\n",
        "    },\n",
        "    {\n",
        "      'key': '_pb',\n",
        "      'label':  'pb'\n",
        "    },\n",
        "    # {\n",
        "    #   'key': '_huevos_de_hemintos',\n",
        "    #   'label':  'huevos_de_hemintos'\n",
        "    # }\n",
        "]\n",
        "\n",
        "category3Probes: List[Dict[str, Union[float, int]]] = [\n",
        "   {\n",
        "     'ATRIBUTE' : '_cloruros',\n",
        "     'NOMINAL' : 'CLORUROS',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_conductividad',\n",
        "     'NOMINAL' : 'CONDUCTIVIDAD',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_dbo',\n",
        "     'NOMINAL' : 'DBO',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_o',\n",
        "     'NOMINAL' : 'O',\n",
        "     'OPERATION': 'greater_or_equal',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_al',\n",
        "     'NOMINAL' : 'AL',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_as_',\n",
        "     'NOMINAL' : 'AS_',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_b',\n",
        "     'NOMINAL' : 'B',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_cd',\n",
        "     'NOMINAL' : 'CD',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_cu',\n",
        "     'NOMINAL' : 'CU',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_fe',\n",
        "     'NOMINAL' : 'FE',\n",
        "     'OPERATION': 'less_than'\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_mn',\n",
        "     'NOMINAL' : 'MN',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_hg',\n",
        "     'NOMINAL' : 'HG',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_pb',\n",
        "     'NOMINAL' : 'PB',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_zn',\n",
        "     'NOMINAL' : 'ZN',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_ph',\n",
        "     'NOMINAL' : 'MIN_PH',\n",
        "     'OPERATION': 'greater_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_ph',\n",
        "     'NOMINAL' : 'MAX_PH',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_coliformes',\n",
        "     'NOMINAL' : 'MAX_NMP_COLIFORMES',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_huevos_de_hemintos',\n",
        "     'NOMINAL' : 'MAX_HUEVOS_DE_EMINTOS',\n",
        "     'OPERATION': 'less_than',\n",
        "   }\n",
        " ]\n",
        "\n",
        "animalDrinkingWaterProbes: List[Dict[str, Union[float, int]]] = [\n",
        "   {\n",
        "     'ATRIBUTE' : '_conductividad',\n",
        "     'NOMINAL' : 'CONDUCTIVIDAD',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_dbo',\n",
        "     'NOMINAL' : 'DBO',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_o',\n",
        "     'NOMINAL' : 'O',\n",
        "     'OPERATION': 'greater_or_equal',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_al',\n",
        "     'NOMINAL' : 'AL',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_as_',\n",
        "     'NOMINAL' : 'AS_',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_b',\n",
        "     'NOMINAL' : 'B',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_cd',\n",
        "     'NOMINAL' : 'CD',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_cu',\n",
        "     'NOMINAL' : 'CU',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_mn',\n",
        "     'NOMINAL' : 'MN',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_hg',\n",
        "     'NOMINAL' : 'HG',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_pb',\n",
        "     'NOMINAL' : 'PB',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_zn',\n",
        "     'NOMINAL' : 'ZN',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_ph',\n",
        "     'NOMINAL' : 'MIN_PH',\n",
        "     'OPERATION': 'greater_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_ph',\n",
        "     'NOMINAL' : 'MAX_PH',\n",
        "     'OPERATION': 'less_than',\n",
        "   },\n",
        "   {\n",
        "     'ATRIBUTE' : '_coliformes',\n",
        "     'NOMINAL' : 'MAX_NMP_COLIFORMES',\n",
        "     'OPERATION': 'less_than',\n",
        "   }\n",
        " ]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyCFZmNU9aPP"
      },
      "source": [
        "# Clases"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clase KNN"
      ],
      "metadata": {
        "id": "CDDF6vXfpCg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    @staticmethod\n",
        "    def EUCLIDIANA(x, y):\n",
        "        return np.sqrt(np.sum((x - y) ** 2))\n",
        "\n",
        "    def aprendizaje(self, X, C):\n",
        "        self.X = X  # matriz de vectores de características\n",
        "        self.c = C  # clases asociadas a cada vector x(n)\n",
        "        self.n_muestras = X.shape[1]  # cantidad de muestras\n",
        "\n",
        "    def clasificacion(self, Y):\n",
        "        clases = []\n",
        "        for i in range(Y.shape[1]):  # por cada vector y(n) a clasificar\n",
        "            distancias = np.empty(self.n_muestras)\n",
        "            for n in range(self.n_muestras):  # por cada vector x(n) de características\n",
        "                distancias[n] = self.EUCLIDIANA(self.X[:, n], Y[:, i])\n",
        "\n",
        "            # distancias más cercanas\n",
        "            k_distancias = np.argsort(distancias)\n",
        "            # identificar las k distancias - clases\n",
        "            k_etiqueta = self.c[k_distancias[:self.k]]\n",
        "            # votación\n",
        "            c = Counter(k_etiqueta).most_common(1)  # (5,0)\n",
        "            clases.append(c[0][0])  # almacenamos la clase asignada al vector y(n)\n",
        "        return clases\n"
      ],
      "metadata": {
        "id": "goA_z-MfpAWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZeLiZ08NTTX"
      },
      "source": [
        "## Clase Eca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyQFHeSMNV0r"
      },
      "outputs": [],
      "source": [
        "class Eca(ABC):\n",
        "\n",
        "  \"\"\"\n",
        "    Representa los valores a conciderar para el cálculo del ICA para agua Categoria 1-A2\n",
        "\n",
        "    Atributos:\n",
        "    - _o : Oxigeno disuelto (valor mínimo) mg/L (float),\n",
        "    - _dbo : Demanda Bioquímica de Oxigeno (DBO5) mg/L (float),\n",
        "    - _as_ : Arsénico mg/L (float),\n",
        "    - _cd : Cadmnio mg/L (float),\n",
        "    - _cu : Cobre mg/L (float),\n",
        "    - _cr : Cromo total mg/L (float),\n",
        "    - _fe : Hierro mg/L (float),\n",
        "    - _mn : Manganeso mg/L (float),\n",
        "    - _pb : Plomo mg/L (float),\n",
        "    - _hg : Mercurio mg/L (float),\n",
        "    - _zn : Zinc mg/L (float),\n",
        "    - _ph : Potencial de Hidrógeno (pH) Unid. de pH (float),\n",
        "    - _coliformes : Coliformes Termotolerantes (44,5°C) NMP/ 100 ml (int)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  _o : float = 0\n",
        "  _dbo : float = 0\n",
        "  _as_ : float = 0\n",
        "  _cd : float = 0\n",
        "  _cu : float = 0\n",
        "  _cr : float = 0\n",
        "  _fe : float = 0\n",
        "  _mn : float = 0\n",
        "  _pb : float = 0\n",
        "  _hg : float = 0\n",
        "  _zn : float = 0\n",
        "  _ph : float = 0\n",
        "  _al : float = 0\n",
        "  _b : float = 0\n",
        "  _coliformes : float = 0\n",
        "  _cloruros : float = 0\n",
        "  _conductividad : float = 0\n",
        "  _huevos_de_hemintos : float = 0\n",
        "\n",
        "  propertynumber : int = 0\n",
        "\n",
        "  NOMINALS: Dict[str, Union[float, int]] = {}\n",
        "  COMPARES : Dict[str,Operation ] = compare_operations\n",
        "  PROBES: List[Dict[str, Union[float, int]]] = []\n",
        "  HEADERSA: List[Dict[str,str]] = []\n",
        "  HEADERSB: List[Dict[str,str]] = []\n",
        "  HEADERSC: List[Dict[str,str]] = []\n",
        "  HEADERSD: List[Dict[str,str]] = []\n",
        "\n",
        "  @abstractmethod\n",
        "  def __init__(self,\n",
        "             _o: float = 0,\n",
        "             _dbo: float = 0,\n",
        "             _as_: float = 0,\n",
        "             _cd: float = 0,\n",
        "             _cu: float = 0,\n",
        "             _cr: float = 0,\n",
        "             _fe: float = 0,\n",
        "             _mn: float = 0,\n",
        "             _pb: float = 0,\n",
        "             _hg: float = 0,\n",
        "             _zn: float = 0,\n",
        "             _ph: float = 0,\n",
        "             _al: float = 0,\n",
        "             _b: float = 0,\n",
        "             _coliformes: float = 0,\n",
        "             _cloruros: float = 0,\n",
        "             _conductividad: float = 0,\n",
        "             _huevos_de_hemintos: float = 0):\n",
        "    self._o = _o\n",
        "    self._dbo = _dbo\n",
        "    self._as_ = _as_\n",
        "    self._cd = _cd\n",
        "    self._cu = _cu\n",
        "    self._cr = _cr\n",
        "    self._fe = _fe\n",
        "    self._mn = _mn\n",
        "    self._pb = _pb\n",
        "    self._hg = _hg\n",
        "    self._zn = _zn\n",
        "    self._ph = _ph\n",
        "    self._al = _al\n",
        "    self._b = _b\n",
        "    self._coliformes = _coliformes\n",
        "    self._cloruros = _cloruros\n",
        "    self._conductividad = _conductividad\n",
        "    self._huevos_de_hemintos = _huevos_de_hemintos\n",
        "\n",
        "  # Getters\n",
        "  @property\n",
        "  def get_o(self) -> float:\n",
        "      return self._o\n",
        "\n",
        "  @property\n",
        "  def get_dbo(self) -> float:\n",
        "      return self._dbo\n",
        "\n",
        "  @property\n",
        "  def get_as_(self) -> float:\n",
        "      return self._as_\n",
        "\n",
        "  @property\n",
        "  def get_cd(self) -> float:\n",
        "      return self._cd\n",
        "\n",
        "  @property\n",
        "  def get_cu(self) -> float:\n",
        "      return self._cu\n",
        "\n",
        "  @property\n",
        "  def get_cr(self) -> float:\n",
        "      return self._cr\n",
        "\n",
        "  @property\n",
        "  def get_fe(self) -> float:\n",
        "      return self._fe\n",
        "\n",
        "  @property\n",
        "  def get_mn(self) -> float:\n",
        "      return self._mn\n",
        "\n",
        "  @property\n",
        "  def get_pb(self) -> float:\n",
        "      return self._pb\n",
        "\n",
        "  @property\n",
        "  def get_hg(self) -> float:\n",
        "      return self._hg\n",
        "\n",
        "  @property\n",
        "  def get_zn(self) -> float:\n",
        "      return self._zn\n",
        "\n",
        "  @property\n",
        "  def get_ph(self) -> float:\n",
        "      return self._ph\n",
        "\n",
        "  @property\n",
        "  def get_coliformes(self) -> float:\n",
        "      return self._coliformes\n",
        "\n",
        "  @property\n",
        "  def get_al(self) -> float:\n",
        "    return self._al\n",
        "\n",
        "  @property\n",
        "  def get_b(self) -> float:\n",
        "    return self._b\n",
        "\n",
        "  @property\n",
        "  def get_cloruros(self) -> float:\n",
        "    return self._cloruros\n",
        "\n",
        "  @property\n",
        "  def get_conductividad(self) -> float:\n",
        "    return self._conductividad\n",
        "\n",
        "  @property\n",
        "  def get_huevos_de_hemintos(self) -> float:\n",
        "    return self._huevos_de_hemintos\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  @abstractmethod\n",
        "  def createFromDF(cls: Type[EcaType] ,df : pd.DataFrame) -> List[EcaType] :\n",
        "    pass\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def createFromExcel(cls: Type[EcaType]) -> List[EcaType] :\n",
        "    \"\"\"\n",
        "    Crea una lista de instancias de  a partir de un archivo de Excel.\n",
        "\n",
        "    Lee los datos de un archivo de Excel utilizando el método `__read_doc`, lo convierte en un DataFrame,\n",
        "    y crea instancias de  para cada fila en el DataFrame.\n",
        "\n",
        "    Returns:\n",
        "        List[]: Una lista de objetos  creados a partir de los datos del Excel.\n",
        "\n",
        "    Raises:\n",
        "        KeyError: Si faltan columnas esperadas en los datos del Excel.\n",
        "        Exception: Para cualquier otro error imprevisto durante el procesamiento.\n",
        "    \"\"\"\n",
        "    #Se lee el archivo y se extrae la data\n",
        "    data = cls.read_doc()\n",
        "\n",
        "    #Se instancia en un data frame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    #Se crea el array a partir del dataframe\n",
        "    categories = cls.createFromDF(df)\n",
        "\n",
        "    return categories\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def read_doc(cls, carpeta : str = './template' ) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Lee datos de un archivo de Excel ubicado en una carpeta específica.\n",
        "\n",
        "    Define la ruta del archivo de Excel y, si el archivo existe, lo lee utilizando `pd.read_excel`\n",
        "    y devuelve el contenido como un DataFrame. Si el archivo no se encuentra, imprime un mensaje de error.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Los datos del archivo de Excel leídos como un DataFrame.\n",
        "\n",
        "    Prints:\n",
        "        str: Mensaje de error si el archivo no se encuentra en la carpeta.\n",
        "    \"\"\"\n",
        "\n",
        "    #Se define el dorectorio para guardar el template\n",
        "    folder_path = f'./content/{carpeta}'\n",
        "\n",
        "    if not os.path.exists(carpeta):\n",
        "      os.makedirs(f'{carpeta}')\n",
        "      print(f\"Directorio '{f'{carpeta}'}' creado.\")\n",
        "      print(f'sube tus archivo de entrenamiento a la carpeta {carpeta}')\n",
        "      return  pd.DataFrame()\n",
        "    archivosEncarpeta = [\n",
        "      os.path.join(os.getcwd(), f'{carpeta}', x)\n",
        "      for x in os.listdir(f'{carpeta}')\n",
        "      if not x.startswith(\".ipynb_checkpoints\")  # Filtrar el archivo .ipynb_checkpoints\n",
        "      ] # genera todas las rutas de los xslx para leerlos\n",
        "    # print(f'La carpeta POS contiene : {str(len(categoria1paths))} archivos')\n",
        "    if len(archivosEncarpeta) ==0:\n",
        "      print(f\"Capeta {carpeta} vacía sube tu excel\")\n",
        "      return  pd.DataFrame()\n",
        "    #Intenta leer el archivo\n",
        "    print(archivosEncarpeta[0],\"----\")\n",
        "    full_path = os.path.join(folder_path, archivosEncarpeta[0])\n",
        "    print(full_path)\n",
        "    if os.path.exists(full_path):\n",
        "        data = pd.read_excel(full_path, engine='openpyxl')\n",
        "        return data\n",
        "\n",
        "    print(f'No se ha encontrado el archivo en la carpeta {carpeta}')\n",
        "    return  pd.DataFrame()\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  def getOutOfRangeAtributtes(self) -> List[str]:\n",
        "\n",
        "    outOfRanges = []\n",
        "\n",
        "    for probe in self.PROBES:\n",
        "\n",
        "      value = getattr(self, str(probe['ATRIBUTE']))\n",
        "      operation = self.COMPARES[str(probe['OPERATION'])]\n",
        "      nominal = self.NOMINALS[str(probe['NOMINAL'])]\n",
        "\n",
        "      result = operation(float(value),nominal)\n",
        "\n",
        "      if not result:\n",
        "        outOfRanges.append(str(probe['ATRIBUTE']))\n",
        "\n",
        "\n",
        "    return list(set(outOfRanges))\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  def getOutOfRangeValues(self) -> int:\n",
        "\n",
        "    outOfRanges = 0\n",
        "\n",
        "    for probe in self.PROBES:\n",
        "\n",
        "      value = getattr(self, str(probe['ATRIBUTE']))\n",
        "      operation = self.COMPARES[str(probe['OPERATION'])]\n",
        "      nominal = self.NOMINALS[str(probe['NOMINAL'])]\n",
        "\n",
        "      result = operation(float(value),nominal)\n",
        "      if not result:\n",
        "        outOfRanges = outOfRanges + 1\n",
        "\n",
        "    return outOfRanges\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def calculateF1(cls : Type[EcaType],arr: List[EcaType]) -> float:\n",
        "\n",
        "    #Se cálculan las\n",
        "    outOfRangeAttributes = []\n",
        "\n",
        "    for category in arr:\n",
        "      outOfRange = category.getOutOfRangeAtributtes()\n",
        "      outOfRangeAttributes.extend(outOfRange)\n",
        "\n",
        "    outOfRangeAttributes = list(set(outOfRangeAttributes))\n",
        "\n",
        "    attributes = cls.propertynumber\n",
        "\n",
        "    return len(outOfRangeAttributes) / attributes\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def calculateF2(cls : Type[EcaType],arr: List[EcaType]) -> float:\n",
        "\n",
        "    #Se cálculan las\n",
        "    outOfRangeValues = 0\n",
        "\n",
        "    for category in arr:\n",
        "      outOfRange = category.getOutOfRangeValues()\n",
        "      outOfRangeValues = outOfRangeValues + outOfRange\n",
        "    attributes = cls.propertynumber * len(arr)\n",
        "\n",
        "    return outOfRangeValues / attributes\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "\n",
        "  @classmethod\n",
        "  def calculateNse(cls : Type[EcaType],arr: List[EcaType]) -> float:\n",
        "\n",
        "    functionCatalog = {\n",
        "        'greater_than':'minor',\n",
        "        'less_than':'major',\n",
        "        'greater_or_equal':'minor',\n",
        "        'less_or_equal':'major',\n",
        "    }\n",
        "\n",
        "    #Se cálculan las\n",
        "    outOfRangeSum = 0\n",
        "\n",
        "    for index, category in enumerate(arr):\n",
        "\n",
        "      for probe in cls.PROBES:\n",
        "        value = getattr(category, str(probe['ATRIBUTE']))\n",
        "        operation = cls.COMPARES[str(probe['OPERATION'])]\n",
        "        nominal = cls.NOMINALS[str(probe['NOMINAL'])]\n",
        "\n",
        "        result = operation(float(value),nominal)\n",
        "        if not result:\n",
        "\n",
        "          if functionCatalog[str(probe['OPERATION'])] == 'minor':\n",
        "            outOfRangeSum = outOfRangeSum + ((nominal/value)-1)\n",
        "\n",
        "\n",
        "          if functionCatalog[str(probe['OPERATION'])] == 'major':\n",
        "            outOfRangeSum = outOfRangeSum + (( value / nominal)-1)\n",
        "\n",
        "\n",
        "    attributes = cls.propertynumber * len(arr)\n",
        "\n",
        "    return outOfRangeSum / attributes\n",
        "\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def calculateF3(cls : Type[EcaType],arr: List[EcaType]) -> float:\n",
        "\n",
        "    #Se cálculan las suma normalizada de excedentes\n",
        "    nse = cls.calculateNse(arr)\n",
        "\n",
        "    return (nse /(nse + 1)) * 100\n",
        "\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def calculateIca(cls : Type[EcaType], arr: List[EcaType]) -> float :\n",
        "    f1 = cls.calculateF1(arr)\n",
        "    f2 = cls.calculateF2(arr)\n",
        "    f3 = cls.calculateF3(arr)\n",
        "    # print(f\"F1={f1}, F2 = {f2}, F3 = {f3}\")\n",
        "\n",
        "    return 100 - (( f1 **2 + f2 **2 + f3**2 )/3)**0.5\n",
        "\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def generar_SVM_multiclass(cls):\n",
        "    # data_etiquetar=cls.leer_para_etiquetado() #Lista de objetos Category1A2\n",
        "    # # print(data_etiquetar)\n",
        "    # if data_etiquetar==None:\n",
        "    #   return None\n",
        "    X,labels=cls.ecaListFromRndDataset(1600)\n",
        "    print(\"Lista de factores \",X)\n",
        "    print(\"Lista de etiquetas \",labels)\n",
        "    # Codificar etiquetas de clase\n",
        "    label_encoder = LabelEncoder()\n",
        "    Y = label_encoder.fit_transform(labels)\n",
        "\n",
        "    # Crear un clasificador SVM con la estrategia \"one-vs-one\"\n",
        "    clf = svm.SVC(decision_function_shape='ovo')\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    clf.fit(X, Y)\n",
        "    # Exportar el modelo\n",
        "    if not os.path.exists(f'./{cls.__name__}'):\n",
        "      os.makedirs(f'./{cls.__name__}')\n",
        "      print(f\"Directorio '{f'./{cls.__name__}'}' creado.\")\n",
        "\n",
        "    modelo=\"modelo_svm.pkl\"\n",
        "    joblib.dump(clf, f'./{cls.__name__}/{modelo}')\n",
        "    print(f\"Modelo exportado como './{cls.__name__}/{modelo}'\")\n",
        "    exito = cls.esperar_modelo(clase_nombre=f\"{cls.__name__}\", archivo=f\"{modelo}\")\n",
        "    if exito:\n",
        "        print(\"Archivo encontrado y listo para su uso.\")\n",
        "    else:\n",
        "        print(\"El archivo no fue encontrado dentro del tiempo de espera especificado.\")\n",
        "\n",
        "    # Guardar también el codificador de etiquetas\n",
        "    etiquetador=\"label_encoder_svm.pkl\"\n",
        "    joblib.dump(label_encoder, f'./{cls.__name__}/{etiquetador}')\n",
        "    print(f\"Codificador de etiquetas exportado como './{cls.__name__}/{etiquetador}'\")\n",
        "    exito = cls.esperar_modelo(clase_nombre=f\"{cls.__name__}\", archivo=f\"{etiquetador}\")\n",
        "    if exito:\n",
        "        print(\"Archivo encontrado y listo para su uso.\")\n",
        "    else:\n",
        "        print(\"El archivo no fue encontrado dentro del tiempo de espera especificado.\")\n",
        "    ### NO BORRAR ESTO (SERVIRÁ CUANDO SE HAGAN LAS OTRAS CATEGORIAS Y SE TENGAN MÁS DATOS)\n",
        "    # # # # # Datos de prueba\n",
        "    # # # # X_test = [[0.3, 0.1, 50]]  # Ejemplo de características para un nuevo dato\n",
        "\n",
        "    # # # # # Realizar predicción\n",
        "    # # # # prediccion = clf.predict(X_test)\n",
        "    # # # # print(\"Predicción:\", label_encoder.inverse_transform(prediccion))  # Decodificar predicción\n",
        "\n",
        "    # # # # # Obtener la función de decisión\n",
        "    # # # # dec = clf.decision_function(X_test)\n",
        "    # # # # print(\"Valores de la función de decisión:\", dec)\n",
        "\n",
        "    # # # # # Verificar la forma de la salida de la función de decisión\n",
        "    # # # # print(\"Forma de la salida de la función de decisión:\", dec.shape)\n",
        "\n",
        "    # # # # # Cambiar la estrategia a \"one-vs-rest\"\n",
        "    # # # # clf.decision_function_shape = \"ovr\"\n",
        "\n",
        "    # # # # # Obtener la función de decisión con la nueva estrategia\n",
        "    # # # # dec = clf.decision_function(X_test)\n",
        "    # # # # print(\"Valores de la función de decisión con 'ovr':\", dec)\n",
        "    # # # # print(\"Forma de la salida de la función de decisión con 'ovr':\", dec.shape)\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def usarModeloSVM(cls,x_predecir) -> str:\n",
        "    # Cargar el modelo\n",
        "    modelo_cargado = joblib.load(f'./{cls.__name__}/modelo_svm.pkl')\n",
        "\n",
        "    # Cargar el codificador de etiquetas\n",
        "    label_encoder_cargado = joblib.load(f'./{cls.__name__}/label_encoder_svm.pkl')\n",
        "\n",
        "    # Realizar predicción con el modelo cargado\n",
        "    prediccion_nueva = modelo_cargado.predict(x_predecir)\n",
        "    # print(\"Nueva Predicción:\", label_encoder_cargado.inverse_transform(prediccion_nueva))\n",
        "    return label_encoder_cargado.inverse_transform(prediccion_nueva)[0]\n",
        "\n",
        "  @classmethod\n",
        "  def leer_para_etiquetado(cls):\n",
        "    listacategoria1=[]\n",
        "    if not os.path.exists(f'./{cls.__name__}_excels'):\n",
        "      os.makedirs(f'./{cls.__name__}_excels')\n",
        "      print(f\"En esta carpeta sube tus excels ./{cls.__name__}_excels\")\n",
        "      return None\n",
        "    categoria1paths = [\n",
        "      os.path.join(os.getcwd(), f'./{cls.__name__}_excels', x)\n",
        "      for x in os.listdir(f'./{cls.__name__}_excels')\n",
        "      if not x.startswith(\".ipynb_checkpoints\")  # Filtrar el archivo .ipynb_checkpoints\n",
        "      ] # genera todas las rutas de los csv para leerlos\n",
        "    # print(f'La carpeta POS contiene : {str(len(categoria1paths))} archivos')\n",
        "    if len(categoria1paths) ==0:\n",
        "      print(\"Capeta vacía sube tu excel\")\n",
        "      return None\n",
        "    for ruta in categoria1paths:\n",
        "      exceltemp=pd.ExcelFile(ruta)\n",
        "      for i in exceltemp.sheet_names:\n",
        "          dftemp = pd.read_excel(ruta, sheet_name=i)\n",
        "          listacategoria1.append(cls.createFromDF(dftemp))\n",
        "\n",
        "          # display(dftemp)\n",
        "          # dftemp.plot(kind='scatter', x='as', y='cu', s=32, alpha=.8)\n",
        "          # plt.gca().spines[['top', 'right',]].set_visible(False)\n",
        "    return listacategoria1\n",
        "\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def etiquetar_dataFrames(cls,listaobjetos):\n",
        "    labels=[]\n",
        "    factoresefe=[]\n",
        "    for periodos in listaobjetos:\n",
        "      valorICA=cls.calculateIca(periodos)\n",
        "      # print(valorICA)\n",
        "      # print(type(valorICA))\n",
        "      etiqueta=cls.asignLabel(valorICA)\n",
        "      labels.append(etiqueta)\n",
        "      f1 = cls.calculateF1(periodos)\n",
        "      f2 = cls.calculateF2(periodos)\n",
        "      f3 = cls.calculateF3(periodos)\n",
        "      factoresefe.append([f1,f2,f3])\n",
        "    return factoresefe,labels\n",
        "\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @staticmethod\n",
        "  def asignLabel(ica : float) -> str :\n",
        "\n",
        "    ica = math.floor(ica)\n",
        "    if 90<=ica <=100:\n",
        "      return \"Excelente\"\n",
        "    elif 75<=ica <90:\n",
        "      return \"Bueno\"\n",
        "    elif 45<=ica <=74:\n",
        "      return \"Regular\"\n",
        "    elif 30<=ica <=44:\n",
        "      return \"Malo\"\n",
        "    elif 0<ica <=29:\n",
        "      return \"Pésimo\"\n",
        "    else:\n",
        "      print(ica)\n",
        "      return \"N/A\"\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def createPlot(\n",
        "      arr: List['EcaType'],\n",
        "      headers: List[Dict[str, str]],\n",
        "      position: int,\n",
        "      total_plots: int\n",
        "  ) -> None:\n",
        "      \"\"\"\n",
        "      Crea una gráfica en una posición específica dentro de una cuadrícula de subplots.\n",
        "      Args:\n",
        "          arr (List[EcaType]): Lista de objetos con datos para graficar.\n",
        "          headers (List[Dict[str, str]]): Lista de diccionarios que contienen la clave y etiqueta para cada línea en la gráfica.\n",
        "          position (int): Posición del subplot en la cuadrícula (1 a total_plots).\n",
        "          total_plots (int): Número total de subplots en la figura.\n",
        "      \"\"\"\n",
        "      import matplotlib.pyplot as plt\n",
        "      # Definir la disposición de la cuadrícula de subplots\n",
        "      rows = cols = int(total_plots ** 0.5)\n",
        "      if rows * cols < total_plots:\n",
        "          cols += 1\n",
        "      # Crear el subplot en la posición especificada\n",
        "      plt.subplot(rows, cols, position)\n",
        "      data = {}\n",
        "      axisX = []\n",
        "      colors = [\n",
        "          'dodgerblue', 'salmon', 'limegreen', 'darkorange', 'deepskyblue',\n",
        "          'purple', 'gold', 'cyan', 'magenta', 'olive',\n",
        "          'navy', 'teal', 'coral', 'orchid', 'sienna',\n",
        "          'grey', 'brown', 'pink', 'lightgreen', 'lavender'\n",
        "      ]\n",
        "      marks = [\n",
        "          '*', 'o', '+', 'x', 's', 'd', '^', 'v', '<', '>',\n",
        "          'p', 'h', 'H', 'D', '|', '_', '.', ',', '1', '2'\n",
        "      ]\n",
        "      # Generar el eje X basado en la longitud de arr\n",
        "      axisX = list(range(1, len(arr) + 1))\n",
        "      # Preparar los datos para cada línea en la gráfica\n",
        "      for key, header in enumerate(headers):\n",
        "          data[header['label']] = [getattr(category, header['key']) for category in arr]\n",
        "      # Graficar cada línea con estilos diferentes\n",
        "      for key, header in enumerate(headers):\n",
        "          plt.plot(\n",
        "              axisX,\n",
        "              data[header['label']],\n",
        "              marker=marks[key % len(marks)],\n",
        "              linestyle='-',\n",
        "              color=colors[key % len(colors)],\n",
        "              label=header['label']\n",
        "          )\n",
        "      plt.xlabel('Muestreos')\n",
        "      plt.ylabel('Mediciones')\n",
        "      plt.title(f'Gráfica {position}')\n",
        "      plt.legend()\n",
        "      plt.grid(True)\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def plotCollection(\n",
        "      cls: Type[EcaType],\n",
        "      arr: List[EcaType],\n",
        "      titles: Dict[str,str]\n",
        "      ) -> None:\n",
        "\n",
        "      plt.figure(figsize=(12, 6))  # Adjust the figure size as needed\n",
        "\n",
        "      cls.createPlot(arr, cls.HEADERSA, position=1,total_plots=4)\n",
        "\n",
        "      cls.createPlot(arr, cls.HEADERSB, position=2, total_plots=4)\n",
        "\n",
        "      cls.createPlot(arr, cls.HEADERSC, position=3, total_plots=4)\n",
        "\n",
        "      cls.createPlot(arr, cls.HEADERSD, position=4, total_plots=4)\n",
        "\n",
        "      fisrtLine = titles['category']\n",
        "      secondLine = f\"ICA calculado     : {titles['ica']}\"\n",
        "      thirthLine = f\"Etiqueta formula : {titles['formula']}\"\n",
        "      fourthLine = f\"Etiqueta svm      : {titles['svm']}\"\n",
        "      fifthLine = f\"Resultado random forest      : {titles['rndmforest']}\"\n",
        "      sextLine = f\"Etiqueta KNN      : {titles['knn']}\"\n",
        "\n",
        "      title = f\"{fisrtLine}\\n{secondLine}\\n{thirthLine}\\n{fourthLine}\\n{fifthLine}\\n{sextLine}\"\n",
        "\n",
        "      plt.suptitle(title, x=0.1, ha='left')  # Ajustar 'x' para mover el título a la izquierda\n",
        "\n",
        "      plt.tight_layout(rect=[0, 0, 1, 0.90])  # Ajustar el diseño para hacer espacio para el título\n",
        "      plt.show()\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def randomDfList(cls,  num_rows: int = 2000) -> List[pd.DataFrame] :\n",
        "    df = cls.read_doc('./entrenamiento')\n",
        "\n",
        "    if df.empty:\n",
        "      print(\"El dataframe está vacio\")\n",
        "      return [pd.DataFrame()]\n",
        "\n",
        "    # Leer las primeras `num_rows` filas del DataFrame\n",
        "    df_subset = df.head(num_rows)\n",
        "\n",
        "    newConfig = {}\n",
        "\n",
        "    for probe in cls.PROBES:\n",
        "\n",
        "      operation = cls.COMPARES[str(probe['OPERATION'])]\n",
        "      nominal = cls.NOMINALS[str(probe['NOMINAL'])]\n",
        "      column = str(probe['ATRIBUTE']).replace('_','')\n",
        "\n",
        "      test = df_subset[column]\n",
        "      newConfig[column] = []\n",
        "\n",
        "      for item in test:\n",
        "\n",
        "        randomNumber = random.uniform(0,nominal * 2.5)\n",
        "        newConfig[column].append(randomNumber if math.isnan(item) or item <=0 else item )\n",
        "\n",
        "    randomDf = pd.DataFrame(newConfig)\n",
        "\n",
        "    randomDf.to_csv('/content/randomDf.csv', index=False)\n",
        "\n",
        "    # Definir el número de filas por DataFrame\n",
        "    rows_per_df = 4\n",
        "\n",
        "    # Crear una lista para almacenar los DataFrames\n",
        "    dataframes_list = []\n",
        "\n",
        "    # Dividir el DataFrame original en partes más pequeñas\n",
        "    for start in range(0, len(randomDf), rows_per_df):\n",
        "        end = start + rows_per_df\n",
        "        df_part = randomDf.iloc[start:end]\n",
        "        dataframes_list.append(df_part)\n",
        "\n",
        "    return dataframes_list\n",
        "\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def cutDataset(cls, num_rows: int = 2000) -> pd.DataFrame:\n",
        "\n",
        "    # guardar_df_en_hojas_aleatorias(randomDf, 'archivo_aleatorio.xlsx')\n",
        "    dataframes_list = cls.randomDfList(num_rows)\n",
        "\n",
        "    ecaList = {\n",
        "        'f1':[],\n",
        "        'f2' :[],\n",
        "        'f3' :[],\n",
        "        'labels' :[]\n",
        "    }\n",
        "\n",
        "    # Imprimir los DataFrames resultantes\n",
        "    for i, df in enumerate(dataframes_list):\n",
        "      reads = cls.createFromDF(df)\n",
        "      ica = cls.calculateIca(reads)\n",
        "      labels = cls.asignLabel(ica)\n",
        "      f1,f2,f3=cls.calculateF1(reads),cls.calculateF2(reads),cls.calculateF3(reads)\n",
        "      ecaList['f1'].append(f1)\n",
        "      ecaList['f2'].append(f2)\n",
        "      ecaList['f3'].append(f3)\n",
        "      ecaList['labels'].append(labels)\n",
        "\n",
        "    trainDf = pd.DataFrame(ecaList)\n",
        "    trainDf.to_csv('/content/randomTrain.csv', index=False)\n",
        "\n",
        "    return trainDf\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def ecaListFromRndDataset(cls, num_rows: int = 2000):\n",
        "    trainDf = cls.cutDataset(num_rows)\n",
        "\n",
        "    fList = []\n",
        "    labels = []\n",
        "\n",
        "    for index, row in trainDf.iterrows():\n",
        "      fList.append([row['f1'],row['f2'],row['f3']])\n",
        "      labels.append(row['labels'])\n",
        "\n",
        "    return fList, labels\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def clasifyKNN(cls, reads : List[List[float]]) -> str:\n",
        "\n",
        "\n",
        "      trainDf = cls.cutDataset()\n",
        "\n",
        "      # Extracción de las características y transposición de la matriz para KNN\n",
        "      X = trainDf[['f1', 'f2', 'f3']].values.T  # Transpuesta para que coincida con la implementación KNN\n",
        "\n",
        "      # Extracción de las etiquetas\n",
        "      C = trainDf['labels'].values\n",
        "\n",
        "      # Convertir las etiquetas a números si es necesario\n",
        "      etiquetas_unicas = list(set(C))\n",
        "      etiquetas_map = {etiqueta: i for i, etiqueta in enumerate(etiquetas_unicas)}\n",
        "      C = np.array([etiquetas_map[etiqueta] for etiqueta in C])\n",
        "\n",
        "      # Graficar los datos de entrenamiento\n",
        "      fig = plt.figure()\n",
        "      ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "      for etiqueta, color, marker in zip(etiquetas_unicas, ['r', 'g', 'b'], ['o', '^', 's']):\n",
        "          # Filtra los datos por etiqueta\n",
        "          idx = np.where(C == etiquetas_map[etiqueta])\n",
        "          ax.scatter(X[0, idx], X[1, idx], X[2, idx], c=color, marker=marker, label=etiqueta)\n",
        "\n",
        "      ax.set_xlabel('f1')\n",
        "      ax.set_ylabel('f2')\n",
        "      ax.set_zlabel('f3')\n",
        "      ax.set_title('Datos de Entrenamiento')\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "      Y = np.array(reads)\n",
        "\n",
        "      clasificador = KNN(k=10)\n",
        "      clasificador.aprendizaje(X, C)  # fase de aprendizaje\n",
        "      clasificar = clasificador.clasificacion(Y)\n",
        "\n",
        "      # Convertir de vuelta a las etiquetas originales\n",
        "      clases_etiquetas = [etiquetas_unicas[clase] for clase in clasificar]\n",
        "\n",
        "      # Retorna las etiquetas clasificadas como una cadena\n",
        "      return clases_etiquetas[0]\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def generar_randomForest_multiclass(cls):\n",
        "    # data_etiquetar=cls.leer_para_etiquetado() #Lista de objetos Category1A2\n",
        "    # # print(data_etiquetar)\n",
        "    # if data_etiquetar==None:\n",
        "    #   return None\n",
        "    X,labels=cls.ecaListFromRndDataset(2000)\n",
        "    print(\"Lista de factores \",X)\n",
        "    print(\"Lista de etiquetas \",labels)\n",
        "    # Codificar etiquetas de clase\n",
        "    label_encoder = LabelEncoder()\n",
        "    Y = label_encoder.fit_transform(labels)\n",
        "    # Codificar las etiquetas de texto a valores numéricos\n",
        "\n",
        "    # Entrenar el clasificador RandomForest\n",
        "    clf_rnd = RandomForestClassifier(random_state=42, n_jobs=-1)#-1 indica que usara todo el poder de computo para el modelo\n",
        "    grid_search= GridSearchCV(clf_rnd,cls.params_grid_random_forest,cv=5,scoring=\"f1_weighted\", return_train_score=True)\n",
        "    grid_search.fit(X, Y)\n",
        "\n",
        "    print(grid_search.best_params_)\n",
        "    print(grid_search.best_estimator_)\n",
        "\n",
        "\n",
        "\n",
        "    # clf_rnd.fit(X, Y)\n",
        "\n",
        "    if not os.path.exists(f'./{cls.__name__}'):\n",
        "      os.makedirs(f'./{cls.__name__}')\n",
        "      print(f\"Directorio '{f'./{cls.__name__}'}' creado.\")\n",
        "\n",
        "    modelo=\"modelo_rnd_forest.pkl\"\n",
        "    # joblib.dump(clf_rnd, f'./{cls.__name__}/{modelo}')\n",
        "    joblib.dump(grid_search.best_estimator_, f'./{cls.__name__}/{modelo}')\n",
        "    print(f\"Modelo exportado como './{cls.__name__}/{modelo}'\")\n",
        "    exito = cls.esperar_modelo(clase_nombre=f\"{cls.__name__}\", archivo=f\"{modelo}\")\n",
        "    if exito:\n",
        "        print(\"Archivo encontrado y listo para su uso.\")\n",
        "    else:\n",
        "        print(\"El archivo no fue encontrado dentro del tiempo de espera especificado.\")\n",
        "\n",
        "    # Guardar también el codificador de etiquetas\n",
        "    etiquetador=\"label_encoder_rnd_forest.pkl\"\n",
        "    joblib.dump(label_encoder, f'./{cls.__name__}/{etiquetador}')\n",
        "    print(f\"Codificador de etiquetas exportado como './{cls.__name__}/{etiquetador}'\")\n",
        "    exito = cls.esperar_modelo(clase_nombre=f\"{cls.__name__}\", archivo=f\"{etiquetador}\")\n",
        "    if exito:\n",
        "        print(\"Archivo encontrado y listo para su uso.\")\n",
        "    else:\n",
        "        print(\"El archivo no fue encontrado dentro del tiempo de espera especificado.\")\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @staticmethod\n",
        "  def esperar_modelo(clase_nombre, archivo='', intervalo=5, timeout=300):\n",
        "    \"\"\"\n",
        "    Espera hasta que el archivo del modelo esté disponible en la carpeta especificada.\n",
        "\n",
        "    :param clase_nombre: Nombre de la clase para formar el nombre de la carpeta.\n",
        "    :param archivo: Nombre del archivo a buscar (por defecto es 'label_encoder.pkl').\n",
        "    :param intervalo: Tiempo en segundos entre cada comprobación (por defecto es 5 segundos).\n",
        "    :param timeout: Tiempo máximo de espera en segundos (por defecto es 300 segundos).\n",
        "    :return: True si el archivo está disponible dentro del tiempo límite, False si se excede el tiempo de espera.\n",
        "    \"\"\"\n",
        "    ruta = f'./{clase_nombre}/{archivo}'\n",
        "    tiempo_esperado = 0\n",
        "\n",
        "    while tiempo_esperado < timeout:\n",
        "        if os.path.exists(ruta):\n",
        "            print(f\"El archivo '{archivo}' está disponible en la carpeta '{clase_nombre}'.\")\n",
        "            return True\n",
        "        time.sleep(intervalo)\n",
        "        tiempo_esperado += intervalo\n",
        "        print(f\"Esperando el archivo '{archivo}' en la carpeta '{clase_nombre}'...\")\n",
        "\n",
        "    print(f\"Tiempo de espera agotado. El archivo '{archivo}' no se encontró en la carpeta '{clase_nombre}'.\")\n",
        "    return False\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def usarModelo_RND_Forest(cls,x_predecir):\n",
        "    # Cargar el modelo\n",
        "    modelo_cargado = joblib.load(f'./{cls.__name__}/modelo_rnd_forest.pkl')\n",
        "\n",
        "    # Cargar el codificador de etiquetas\n",
        "    label_encoder_cargado = joblib.load(f'./{cls.__name__}/label_encoder_rnd_forest.pkl')\n",
        "\n",
        "    # Realizar predicción con el modelo cargado\n",
        "    prediccion_nueva = modelo_cargado.predict(x_predecir)\n",
        "    return label_encoder_cargado.inverse_transform(prediccion_nueva)[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cMf4quHNaNp"
      },
      "source": [
        "## Clase Category1A2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nWXaCTWNtXO"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Category1A2(Eca):\n",
        "  params_grid_random_forest=[\n",
        "      #Probará con 50,100,150 arboles de desición en el randomforest\n",
        "      {\"n_estimators\":[50,100,150]},\n",
        "  ]\n",
        "  NOMINALS: Dict[str, Union[float, int]] = category1A2Nominals\n",
        "  PROBES: List[Dict[str, Union[float, int]]] = category1A2Probes\n",
        "  propertynumber : int = catgory1A2Propertynumber\n",
        "  HEADERSA: List[Dict[str,str]] = category1A2HeadersA\n",
        "  HEADERSB: List[Dict[str,str]] = category1A2HeadersB\n",
        "  HEADERSC: List[Dict[str,str]] = category1A2HeadersC\n",
        "  HEADERSD: List[Dict[str,str]] = category1A2HeadersD\n",
        "\n",
        "  #constructor\n",
        "  def __init__(self,\n",
        "               o: float,\n",
        "               dbo: float,\n",
        "               as_: float,\n",
        "               cd: float,\n",
        "               cu: float,\n",
        "               cr: float,\n",
        "               fe: float,\n",
        "               mn: float,\n",
        "               pb: float,\n",
        "               hg: float,\n",
        "               zn: float,\n",
        "               ph: float,\n",
        "               coliformes: float):\n",
        "                super().__init__(_o = o, _dbo = dbo, _as_ = as_,\n",
        "                                 _cd = cd, _cu = cu, _cr = cr, _fe = fe, _mn = mn, _pb = pb, _hg = hg, _zn = zn, _ph = ph, _coliformes = coliformes)\n",
        "  #-----------------------------------------------------------------------------\n",
        "  @classmethod\n",
        "  def createFromDF(cls,df : pd.DataFrame) -> List['Category1A2'] :\n",
        "    \"\"\"\n",
        "    Crea una lista de instancias de Category1A2 a partir de un DataFrame.\n",
        "\n",
        "    Itera sobre cada fila del DataFrame y crea una instancia de Category1A2\n",
        "    para cada una, añadiéndola a una lista.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame que contiene los datos para crear instancias de Category1A2.\n",
        "\n",
        "    Returns:\n",
        "        List[Category1A2]: Una lista de objetos Category1A2 creados a partir de los datos del DataFrame.\n",
        "\n",
        "    Raises:\n",
        "        KeyError: Si alguna columna esperada falta en el DataFrame.\n",
        "        Exception: Para cualquier otro error imprevisto durante el procesamiento.\n",
        "    \"\"\"\n",
        "    categories = []\n",
        "    try:\n",
        "\n",
        "      for _, row in df.iterrows():\n",
        "\n",
        "          category = cls(\n",
        "              o=row['o'], dbo=row['dbo'], as_=row['as'], cd=row['cd'], cu=row['cu'],\n",
        "              cr=row['cr'], fe=row['fe'], mn=row['mn'], pb=row['pb'], hg=row['hg'],\n",
        "              zn=row['zn'], ph=row['ph'], coliformes=row['coliformes']\n",
        "          )\n",
        "          categories.append(category)\n",
        "    except KeyError as e:\n",
        "        print(f\"Error de clave: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ocurrió un error: {e}\")\n",
        "    return categories\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DHgswZwZ3bw"
      },
      "source": [
        "##Clase Category3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8sBYkCkaAi0"
      },
      "outputs": [],
      "source": [
        "class Category3(Eca):\n",
        "  params_grid_random_forest=[\n",
        "      #Probará con 100,150,200 arboles de desición en el randomforest\n",
        "      {\"n_estimators\":[100,150,200]},\n",
        "  ]\n",
        "  propertynumber : int = category3Propertynumber\n",
        "  PROBES: List[Dict[str, Union[float, int]]] = category3Probes\n",
        "\n",
        "  HEADERSA: List[Dict[str,str]] = category3HeadersA\n",
        "  HEADERSB: List[Dict[str,str]] = category3HeadersB\n",
        "  HEADERSC: List[Dict[str,str]] = category3HeadersC\n",
        "  HEADERSD: List[Dict[str,str]] = category3HeadersD\n",
        "\n",
        "  #constructor\n",
        "  @abstractmethod\n",
        "  def _init_(\n",
        "      self,\n",
        "      cloruros: float,\n",
        "      conductividad: float,\n",
        "      dbo: float,\n",
        "      o: float,\n",
        "      ph: float,\n",
        "      al: float,\n",
        "      as_: float,\n",
        "      b: float,\n",
        "      cd: float,\n",
        "      cu: float,\n",
        "      fe: float,\n",
        "      mn: float,\n",
        "      hg: float,\n",
        "      pb: float,\n",
        "      zn: float,\n",
        "      coliformes: float,\n",
        "      huevos_de_hemintos:float\n",
        "      ):\n",
        "        super()._init( _cloruros = cloruros, _conductividad = conductividad, _dbo = dbo, _o = o, _ph = ph, _al = al, _as = as_, _b = b, _cd = cd, _cu = cu, _fe = fe, _mn = mn, _hg = hg, _pb = pb, _zn = zn, _coliformes = coliformes, _huevos_de_hemintos = huevos_de_hemintos,\n",
        "        )\n",
        "\n",
        "\n",
        "  #-----------------------------------------------------------------------------\n",
        "\n",
        "  @classmethod\n",
        "  def createFromDF(\n",
        "      cls : Type[Category3Type],\n",
        "      df : pd.DataFrame) -> List[Category3Type] :\n",
        "\n",
        "    \"\"\"\n",
        "    Crea una lista de instancias de Category1A2 a partir de un DataFrame.\n",
        "\n",
        "    Itera sobre cada fila del DataFrame y crea una instancia de Category1A2\n",
        "    para cada una, añadiéndola a una lista.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame que contiene los datos para crear instancias de Category1A2.\n",
        "\n",
        "    Returns:\n",
        "        List[Category1A2]: Una lista de objetos Category1A2 creados a partir de los datos del DataFrame.\n",
        "\n",
        "    Raises:\n",
        "        KeyError: Si alguna columna esperada falta en el DataFrame.\n",
        "        Exception: Para cualquier otro error imprevisto durante el procesamiento.\n",
        "    \"\"\"\n",
        "    categories = []\n",
        "    try:\n",
        "\n",
        "      for _, row in df.iterrows():\n",
        "\n",
        "          category = cls(\n",
        "              cloruros = row['cloruros'],conductividad = row['conductividad'], dbo = row['dbo'], o = row['o'], ph = row['ph'], al = row['al'], as_ = row['as'], b = row['b'], cd = row['cd'], cu = row['cu'],\n",
        "              fe = row['fe'], mn = row['mn'], hg = row['hg'], pb = row['pb'], zn = row['zn'], coliformes = row['coliformes'], huevos_de_hemintos = row['huevos de hemintos'],\n",
        "          )\n",
        "\n",
        "          categories.append(category)\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error de clave: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ocurrió un error: {e}\")\n",
        "    return categories\n",
        "\n",
        "  #-----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLi1ijzncugy"
      },
      "source": [
        "## Clase RestrictedIrrigation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiwZByOydS1H"
      },
      "outputs": [],
      "source": [
        "class RestrictedIrrigation(Category3):\n",
        "\n",
        "  NOMINALS: Dict[str, Union[float, int]] = restrictedIrrigationNominals\n",
        "\n",
        "  def __init__(\n",
        "      self, cloruros: float, conductividad: int, dbo: float, o: float, ph: float, al: float, as_: float, b: float, cd: float, cu: float, fe: float, mn: float, hg: float, pb: float, zn: float, coliformes: float, huevos_de_hemintos: int\n",
        "      ):\n",
        "        super().__init__(\n",
        "            cloruros=cloruros, conductividad=conductividad, dbo=dbo, o=o, ph=ph, al=al,\n",
        "            as_=as_, b=b, cd=cd, cu=cu, fe=fe, mn=mn, hg=hg, pb=pb, zn=zn, coliformes=coliformes,\n",
        "            huevos_de_hemintos=huevos_de_hemintos\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiXG9ZJo0bJp"
      },
      "source": [
        "## Clase NoRestrictedIrrigation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqBjwZvG0bJu"
      },
      "outputs": [],
      "source": [
        "class NoRestrictedIrrigation(Category3):\n",
        "\n",
        "  NOMINALS: Dict[str, Union[float, int]] = noRestrictedIrrigationNominals\n",
        "\n",
        "  def __init__(\n",
        "      self, cloruros: float, conductividad: int, dbo: float, o: float, ph: float, al: float, as_: float, b: float, cd: float, cu: float, fe: float, mn: float, hg: float, pb: float, zn: float, coliformes: int, huevos_de_hemintos: int\n",
        "      ):\n",
        "        super().__init__(\n",
        "            cloruros=cloruros, conductividad=conductividad, dbo=dbo, o=o, ph=ph, al=al,\n",
        "            as_=as_, b=b, cd=cd, cu=cu, fe=fe, mn=mn, hg=hg, pb=pb, zn=zn, coliformes=coliformes,\n",
        "            huevos_de_hemintos=huevos_de_hemintos\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCnZRFRAvgDH"
      },
      "source": [
        "## Clase AnimalDrinkingWater"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MsXK7UJvgDM"
      },
      "outputs": [],
      "source": [
        "class AnimalDrinkingWater(Category3):\n",
        "\n",
        "  NOMINALS: Dict[str, Union[float, int]] = animalDrinkingWaterNominals\n",
        "  PROBES: List[Dict[str, Union[float, int]]] = animalDrinkingWaterProbes\n",
        "\n",
        "  def _init_(\n",
        "      self, conductividad: float, dbo: float, o: float, ph: float, al: float, as_: float, b: float, cd: float, cu: float, mn: float, hg: float, pb: float, zn: float, coliformes: float\n",
        "      ):\n",
        "        super()._init_(\n",
        "            cloruros=0, conductividad=conductividad, dbo=dbo, o=o, ph=ph, al=al,\n",
        "            as_=as_, b=b, cd=cd, cu=cu, fe=0, mn=mn, hg=hg, pb=pb, zn=zn, coliformes=coliformes,\n",
        "            huevos_de_hemintos=0\n",
        "        )\n",
        "\n",
        "  @classmethod\n",
        "  def createFromDF(\n",
        "      cls : Type[Category3Type],\n",
        "      df : pd.DataFrame) -> List[Category3Type] :\n",
        "\n",
        "    \"\"\"\n",
        "    Crea una lista de instancias de Category1A2 a partir de un DataFrame.\n",
        "\n",
        "    Itera sobre cada fila del DataFrame y crea una instancia de Category1A2\n",
        "    para cada una, añadiéndola a una lista.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame que contiene los datos para crear instancias de Category1A2.\n",
        "\n",
        "    Returns:\n",
        "        List[Category1A2]: Una lista de objetos Category1A2 creados a partir de los datos del DataFrame.\n",
        "\n",
        "    Raises:\n",
        "        KeyError: Si alguna columna esperada falta en el DataFrame.\n",
        "        Exception: Para cualquier otro error imprevisto durante el procesamiento.\n",
        "    \"\"\"\n",
        "    categories = []\n",
        "    try:\n",
        "\n",
        "      for _, row in df.iterrows():\n",
        "\n",
        "          category = cls(\n",
        "              conductividad = row['conductividad'], dbo = row['dbo'], o = row['o'], ph = row['ph'], al = row['al'], as_ = row['as'], b = row['b'], cd = row['cd'], cu = row['cu'], mn = row['mn'], hg = row['hg'], pb = row['pb'], zn = row['zn'], coliformes = row['coliformes']\n",
        "          )\n",
        "\n",
        "          categories.append(category)\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error de clave: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ocurrió un error: {e}\")\n",
        "    return categories"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Entrenamiento\n",
        "##SVM\n"
      ],
      "metadata": {
        "id": "ENmPZRRs8BHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train() -> None:\n",
        "    #Genera SVM\n",
        "    # Category1A2.generar_SVM_multiclass()### lee directamente de la carpeta Category1A2\n",
        "    # RestrictedIrrigation.generar_SVM_multiclass()### lee directamente de la carpeta RestrictedIrrigation\n",
        "    # NoRestrictedIrrigation.generar_SVM_multiclass()### lee directamente de la carpeta NoRestrictedIrrigation\n",
        "    AnimalDrinkingWater.generar_SVM_multiclass()### lee directamente de la carpeta AnimalDrinkingWater\n",
        "\n",
        "    #Genera random forest\n",
        "    # Category1A2.generar_randomForest_multiclass()### lee directamente de la carpeta Category1A2\n",
        "    # RestrictedIrrigation.generar_randomForest_multiclass()### lee directamente de la carpeta RestrictedIrrigation\n",
        "    # NoRestrictedIrrigation.generar_randomForest_multiclass()### lee directamente de la carpeta NoRestrictedIrrigation\n",
        "    AnimalDrinkingWater.generar_randomForest_multiclass()### lee directamente de la carpeta AnimalDrinkingWater\n"
      ],
      "metadata": {
        "id": "MX_1GSx17_EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpYnQrLNLRmR"
      },
      "source": [
        "# Algoritmos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7SsBsI6SPYF"
      },
      "source": [
        "##Categoría 1A2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STzxeXVkApna"
      },
      "outputs": [],
      "source": [
        "def ica_Category1A2() -> None:\n",
        "\n",
        "  print(\"\\n\\n\\n\")\n",
        "\n",
        "  #Se lee el archivo template\n",
        "  reads = Category1A2.createFromExcel()\n",
        "  if(len(reads) == 0): #Si hay un error retorna\n",
        "    return\n",
        "\n",
        "  #Cálculo del ica\n",
        "  ica = Category1A2.calculateIca(reads)\n",
        "  labelAsigned = Category1A2.asignLabel(ica)\n",
        "\n",
        "  f1,f2,f3=Category1A2.calculateF1(reads),Category1A2.calculateF2(reads),Category1A2.calculateF3(reads)\n",
        "  x=[[f1,f2,f3]]\n",
        "\n",
        "  svm = Category1A2.usarModeloSVM(x)##usa el modelo SVM\n",
        "\n",
        "  rndmforest = Category1A2.usarModelo_RND_Forest(x)\n",
        "  knn = Category1A2.clasifyKNN([[f1],[f2],[f3]])\n",
        "\n",
        "  titles : Dict[str,str] = {\n",
        "      'category' : 'Categoria 1A2',\n",
        "      'ica' : str(round(ica,2)),\n",
        "      'formula' : labelAsigned,\n",
        "      'svm' : svm,\n",
        "      'rndmforest' : rndmforest,\n",
        "      'knn' : knn\n",
        "  }\n",
        "  Category1A2.plotCollection(reads,titles)\n",
        "\n",
        "  ##----------------Revisar manejo de errores de svm ------------------\n",
        "\n",
        "  # Category1A2.generar_SVM_multiclass()### lee directamente de la carpeta Category1A2_excels\n",
        "\n",
        "\n",
        "  # Category1A2.usarModeloSVM(x)##usa el modelo SVM\n",
        "\n",
        "  #Predecir KNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z_8FVuqWvwo"
      },
      "source": [
        "## Categoría 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJJbpPpqXFxz"
      },
      "source": [
        "### Riego Restringido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e038PZA-d21h"
      },
      "outputs": [],
      "source": [
        "def ica_RestrictedIrrigation() -> None :\n",
        "\n",
        "  print(\"\\n\")\n",
        "  #Se lee el archivo template\n",
        "  reads = RestrictedIrrigation.createFromExcel()\n",
        "  if(len(reads) == 0): #Si hay un error retorna\n",
        "    return\n",
        "\n",
        "  #--------------------ICA-----------------------\n",
        "  ica = RestrictedIrrigation.calculateIca(reads)\n",
        "  labelAsigned = RestrictedIrrigation.asignLabel(ica)\n",
        "\n",
        "  ##----------------SVM------------------\n",
        "  f1,f2,f3=RestrictedIrrigation.calculateF1(reads),RestrictedIrrigation.calculateF2(reads),RestrictedIrrigation.calculateF3(reads)\n",
        "  x=[[f1,f2,f3]]\n",
        "  svm = RestrictedIrrigation.usarModeloSVM(x)##usa el modelo SVM\n",
        "  rndmforest = RestrictedIrrigation.usarModelo_RND_Forest(x)##usa el modelo randomforest\n",
        "  ##-----------------Plot-----------------\n",
        "  titles : Dict[str,str] = {\n",
        "      'category' : 'Categoria 3 Riego Restringido',\n",
        "      'ica' : str(round(ica,2)),\n",
        "      'formula' : labelAsigned,\n",
        "      'svm' : svm,\n",
        "      'rndmforest':rndmforest\n",
        "  }\n",
        "  RestrictedIrrigation.plotCollection(reads,titles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCRFSfNXOnL"
      },
      "source": [
        "### Riego No Restringido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHwpSX7avU7t"
      },
      "outputs": [],
      "source": [
        "def ica_NoRestrictedIrrigation() -> None :\n",
        "\n",
        "  print(\"\\n\")\n",
        "  #Se lee el archivo template\n",
        "  reads = NoRestrictedIrrigation.createFromExcel()\n",
        "  if(len(reads) == 0): #Si hay un error retorna\n",
        "    return\n",
        "\n",
        "  ##----------------ICA-----------------------\n",
        "  ica = NoRestrictedIrrigation.calculateIca(reads)\n",
        "  labelAsigned = NoRestrictedIrrigation.asignLabel(ica)\n",
        "\n",
        "  ##----------------SVM------------------\n",
        "  f1,f2,f3=NoRestrictedIrrigation.calculateF1(reads),NoRestrictedIrrigation.calculateF2(reads),NoRestrictedIrrigation.calculateF3(reads)\n",
        "  x=[[f1,f2,f3]]\n",
        "  svm =  NoRestrictedIrrigation.usarModeloSVM(x)##usa el modelo SVM\n",
        "  rndmforest = NoRestrictedIrrigation.usarModelo_RND_Forest(x)##usa el modelo randomforest\n",
        "  ##----------------Plot---------------------------------\n",
        "  titles : Dict[str,str] = {\n",
        "      'category' : 'Categoria 3 Riego No Restringido',\n",
        "      'ica' : str(round(ica,2)),\n",
        "      'formula' : labelAsigned,\n",
        "      'svm' : svm,\n",
        "      'rndmforest':rndmforest\n",
        "\n",
        "  }\n",
        "\n",
        "  NoRestrictedIrrigation.plotCollection(reads,titles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcV5hL8iXl-G"
      },
      "source": [
        "### Bebida de animales"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ica_AnimalDrinkingWater() -> None :\n",
        "\n",
        "  print(\"\\n\")\n",
        "  #Se lee el archivo template\n",
        "  reads = AnimalDrinkingWater.createFromExcel()\n",
        "  if(len(reads) == 0): #Si hay un error retorna\n",
        "    return\n",
        "\n",
        "  ##----------------ICA------------------------\n",
        "  ica = AnimalDrinkingWater.calculateIca(reads)\n",
        "  labelAsigned = AnimalDrinkingWater.asignLabel(ica)\n",
        "\n",
        "  ##----------------SVM------------------\n",
        "  f1,f2,f3=AnimalDrinkingWater.calculateF1(reads),AnimalDrinkingWater.calculateF2(reads),AnimalDrinkingWater.calculateF3(reads)\n",
        "  x=[[f1,f2,f3]]\n",
        "  svm = AnimalDrinkingWater.usarModeloSVM(x)##usa el modelo SVM\n",
        "  rndmforest = AnimalDrinkingWater.usarModelo_RND_Forest(x)##usa el modelo randomforest\n",
        "  #-----------------Plot------------------\n",
        "  titles : Dict[str,str] = {\n",
        "      'category' : 'Categoria 3 Bebida de animales',\n",
        "      'ica' : str(round(ica,2)),\n",
        "      'formula' : labelAsigned,\n",
        "      'svm' : svm,\n",
        "      'rndmforest':rndmforest\n",
        "\n",
        "  }\n",
        "  AnimalDrinkingWater.plotCollection(reads,titles)"
      ],
      "metadata": {
        "id": "uEl5joIS-8AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mY-Sx4wcKkF"
      },
      "source": [
        "## Función Principal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEuHkXgScW2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5e6e0943-eae2-4d56-8e97-633a095ced5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/./entrenamiento/randomDf_final_train_categoria_bebida_animal.xlsx ----\n",
            "/content/./entrenamiento/randomDf_final_train_categoria_bebida_animal.xlsx\n",
            "Ocurrió un error: Can't instantiate abstract class AnimalDrinkingWater with abstract method __init__\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-95d896f48caa>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mica_AnimalDrinkingWater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0m__CALCULATE_ICA__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-95d896f48caa>\u001b[0m in \u001b[0;36m__CALCULATE_ICA__\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__CALCULATE_ICA__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# ica_Category1A2()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-973d8b96c914>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# RestrictedIrrigation.generar_SVM_multiclass()### lee directamente de la carpeta RestrictedIrrigation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# NoRestrictedIrrigation.generar_SVM_multiclass()### lee directamente de la carpeta NoRestrictedIrrigation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mAnimalDrinkingWater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerar_SVM_multiclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m### lee directamente de la carpeta AnimalDrinkingWater\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#Genera random forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-58698e8c1f8d>\u001b[0m in \u001b[0;36mgenerar_SVM_multiclass\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;31m# if data_etiquetar==None:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;31m#   return None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mecaListFromRndDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Lista de factores \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Lista de etiquetas \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-58698e8c1f8d>\u001b[0m in \u001b[0;36mecaListFromRndDataset\u001b[0;34m(cls, num_rows)\u001b[0m\n\u001b[1;32m    676\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mecaListFromRndDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0mtrainDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcutDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mfList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-58698e8c1f8d>\u001b[0m in \u001b[0;36mcutDataset\u001b[0;34m(cls, num_rows)\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframes_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m       \u001b[0mreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateFromDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m       \u001b[0mica\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculateIca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masignLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mica\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m       \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculateF1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculateF2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculateF3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-58698e8c1f8d>\u001b[0m in \u001b[0;36mcalculateIca\u001b[0;34m(cls, arr)\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcalculateIca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEcaType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEcaType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculateF1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m     \u001b[0mf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculateF2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0mf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculateF3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;31m# print(f\"F1={f1}, F2 = {f2}, F3 = {f3}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-58698e8c1f8d>\u001b[0m in \u001b[0;36mcalculateF2\u001b[0;34m(cls, arr)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropertynumber\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0moutOfRangeValues\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m   \u001b[0;31m#-----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ],
      "source": [
        "def __CALCULATE_ICA__():\n",
        "\n",
        "  train()\n",
        "\n",
        "  # ica_Category1A2()\n",
        "\n",
        "  ica_AnimalDrinkingWater()\n",
        "\n",
        "__CALCULATE_ICA__()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hasta aquí codigo chido"
      ],
      "metadata": {
        "id": "PigONmbzp22w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###SVM(Suport Vector Machine)\n",
        "##Multi-class classification"
      ],
      "metadata": {
        "id": "jVPGSu0dSW9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets, svm\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "\n",
        "# import some data to play with\n",
        "# iris = datasets.load_iris()\n",
        "# Take the first two features. We could avoid this by using a two-dim dataset\n",
        "X = factoresefe\n",
        "Y = labels\n",
        "\n",
        "# we create an instance of SVM and fit out data. We do not scale our\n",
        "# data since we want to plot the support vectors\n",
        "C = 1.0  # SVM regularization parameter\n",
        "models = (\n",
        "    svm.SVC(kernel=\"linear\", C=C),\n",
        "    svm.LinearSVC(C=C, max_iter=10000),\n",
        "    svm.SVC(kernel=\"rbf\", gamma=0.7, C=C),\n",
        "    svm.SVC(kernel=\"poly\", degree=3, gamma=\"auto\", C=C),\n",
        "    svm.SVC(decision_function_shape='ovo')\n",
        "\n",
        ")\n",
        "models = (clf.fit(X, y) for clf in models)\n",
        "\n",
        "# title for the plots\n",
        "titles = (\n",
        "    \"SVC with linear kernel\",\n",
        "    \"LinearSVC (linear kernel)\",\n",
        "    \"SVC with RBF kernel\",\n",
        "    \"SVC with polynomial (degree 3) kernel\",\n",
        ")\n",
        "\n",
        "# Set-up 2x2 grid for plotting.\n",
        "fig, sub = plt.subplots(2, 2)\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
        "\n",
        "X0, X1 = X[0], X[1]\n",
        "\n",
        "for clf, title, ax in zip(models, titles, sub.flatten()):\n",
        "    disp = DecisionBoundaryDisplay.from_estimator(\n",
        "        clf,\n",
        "        X,\n",
        "        response_method=\"predict\",\n",
        "        cmap=plt.cm.coolwarm,\n",
        "        alpha=0.8,\n",
        "        ax=ax,\n",
        "        # xlabel=iris.feature_names[0],\n",
        "        # ylabel=iris.feature_names[1],\n",
        "    )\n",
        "    ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "    ax.set_title(title)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sf-7h5gXpytA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Datos de entrada (características)\n",
        "X = [[0.5384615384615384, 0.34615384615384615, 71.50487223318459],\n",
        "     [0.5384615384615384, 0.1958041958041958, 97.5080952054009],\n",
        "     [0.07692307692307693, 0.019230769230769232, 10.318913190095385]]\n",
        "\n",
        "# Etiquetas de clase\n",
        "labels = ['Regular', 'Malo', 'Excelente']\n",
        "\n",
        "# Codificar etiquetas de clase\n",
        "label_encoder = LabelEncoder()\n",
        "Y = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Crear un clasificador SVM con la estrategia \"one-vs-one\"\n",
        "clf = svm.SVC(decision_function_shape='ovo')\n",
        "\n",
        "# Entrenar el modelo\n",
        "clf.fit(X, Y)\n",
        "\n",
        "# Datos de prueba\n",
        "X_test = [[0.3, 0.1, 50]]  # Ejemplo de características para un nuevo dato\n",
        "\n",
        "# Realizar predicción\n",
        "prediccion = clf.predict(X_test)\n",
        "print(\"Predicción:\", label_encoder.inverse_transform(prediccion))  # Decodificar predicción\n",
        "\n",
        "# Obtener la función de decisión\n",
        "dec = clf.decision_function(X_test)\n",
        "print(\"Valores de la función de decisión:\", dec)\n",
        "\n",
        "# Verificar la forma de la salida de la función de decisión\n",
        "print(\"Forma de la salida de la función de decisión:\", dec.shape)\n",
        "\n",
        "# Cambiar la estrategia a \"one-vs-rest\"\n",
        "clf.decision_function_shape = \"ovr\"\n",
        "\n",
        "# Obtener la función de decisión con la nueva estrategia\n",
        "dec = clf.decision_function(X_test)\n",
        "print(\"Valores de la función de decisión con 'ovr':\", dec)\n",
        "print(\"Forma de la salida de la función de decisión con 'ovr':\", dec.shape)\n"
      ],
      "metadata": {
        "id": "Y-IAyc4ESV3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.decision_function_shape = \"ovr\"\n",
        "dec = clf.decision_function([factoresefe[0]])\n",
        "dec.shape[1] # 4 classes"
      ],
      "metadata": {
        "id": "K9LdLCVCVY4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Leer los excels originales"
      ],
      "metadata": {
        "id": "m1D6jsWWNPHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categoria1=[]\n",
        "categoria2=[]\n",
        "categoria3=[]\n",
        "contador1=0\n",
        "contador2=0\n",
        "contador3=0\n",
        "archivosDict=[\n",
        "    {\"ruta\":\"/content/./exceles_carpeta/Monetoreo_de_parametros_cuenca_Huarmey_2023_data.xlsx\",\"especificaciones\":{\n",
        "        \"hojas\": {\n",
        "            \"c1\":{\"inicio\":\"B:P\",\"skiprows\":8,\"categoría\":1},\n",
        "            \"c2\":{\"inicio\":\"B:J\",\"skiprows\":8,\"categoría\":2}\n",
        "            },\n",
        "        \"nuevosTitulos\":{\n",
        "            \"c1\":[\"Parametro\",\n",
        "                  \"Unidades\",\n",
        "                  \"ECA - Agua, D.S N°004-2017 - MINAM. Categoría 1: Poblacional y recreacional. Subcategoría A: Aguas superficiales destinadas a la producción de agua. A2: Aguas que pueden ser potabilizadas con tratamiento convencional.\",\n",
        "                  \"QHerc1\",\"QHerc2\",\"QHerc3\",\"QSant1\",\"QYact1\",\"Agua para riego no\",\"Agua parariego restringido\",\"D2: Bebida de Animales\",\"QMont2\",\"QPall3\",\"RAija1\",\"Datos Resaltados\"],\n",
        "            \"c2\":[\"Parametro\",\n",
        "                  \"Unidades\",\n",
        "                  \"ECA - Agua, D.S N°004-2017 - MINAM. Categoría 1: Poblacional y recreacional. Subcategoría B: Aguas superficiales destinadas para recreación. B1: Contacto Primario.\",\n",
        "                  \"MHuar2S\",\"MHuar3S\",\"MHuar4S\",\"MHuar5\",\"MHuar7\",\"Datos Resaltados\"]\n",
        "            },\n",
        "        }},\n",
        "    {\"ruta\":\"/content/./exceles_carpeta/Montoreo_de_parametros_de_agua_cuenca_Huarmey_2020_data.xlsx\",\"especificaciones\":{\n",
        "        \"hojas\": {\n",
        "            \"Eca3\":{\"inicio\":\"B:P\",\"skiprows\":6,\"categoría\":3},\n",
        "            \"Eca3M\":{\"inicio\":\"B:M\",\"skiprows\":6,\"categoría\":3},\n",
        "            \"Eca1\":{\"inicio\":\"B:I\",\"skiprows\":6,\"categoría\":1}\n",
        "            },\n",
        "        \"nuevosTitulos\":{\n",
        "            \"Eca3\":[\"Parametro\",\"Unidades\",\"Riesgo no restringido\",\"Riesgo restringido\",\"D2:Bebida de animales\",\"QMont1\",\"QMont2\",\"QMont3\",\"QHuin1\",\"RLlac1\",\"QHerc3\",\"QPall1\",\"QSant1\",\"QSant2\",\"Datos Resaltados\"],\n",
        "            \"Eca3M\":[\"Parametro\",\"Unidades\",\"Riesgo no restringido\",\"Riesgo restringido\",\"D2:Bebida de animales\",\"Rsant1\",\"RAija1\",\"RCota3\",\"RCota2\",\"RAija4\",\"RAija3\",\"DatosResaltados\"],\n",
        "            \"Eca1\":[\"Parametro\",\"Unidades\",\"ECA - AGUA CATEG.1-A2\",\"RLame1\",\"RLame2\",\"RMall1\",\"RMall2\",\"Datos Resaltados\"]\n",
        "            },        }},\n",
        "    {\"ruta\":\"/content/./exceles_carpeta/Monetoreo_de_parametros_cuenca_Huarmey_2021_data.xlsx\",\"especificaciones\":{\n",
        "        \"hojas\": {\n",
        "            \"eca1\":{\"inicio\":\"B:P\",\"skiprows\":12,\"categoría\":1},\n",
        "            \"eca1.2\":{\"inicio\":\"B:P\",\"skiprows\":12,\"categoría\":1},\n",
        "            \"eca2\":{\"inicio\":\"B:V\",\"skiprows\":12,\"categoría\":2},\n",
        "            \"eca2.3\":{\"inicio\":\"B:V\",\"skiprows\":12,\"categoría\":2}\n",
        "            },\n",
        "        \"nuevosTitulos\":{\n",
        "            \"eca1\":[\"Parametro\",\"Unidades\",\"Cat.1-A2\",\"QHero3\",\"QHuin1\",\"QMacs2\",\"QNnom2\",\"QSant1\",\"QSant4\",\"QYact1\",\"RLmer1\",\"RLmer2\",\"RSant1\",\"RYact1\",\"Datos Resaltados\"],\n",
        "            \"eca1.2\":[\"Parametro\",\"Unidades\",\"Cat.1-A2\",\"QHero3\",\"QHuin1\",\"QMacs2\",\"QNnom2\",\"QSant1\",\"QSant4\",\"QYact1\",\"RLmer1\",\"RLmer2\",\"RSant1\",\"RYact1\",\"Datos Resaltados\"],\n",
        "            \"eca2\":[\"Parametro\",\"Unidades\",\"Cat.3-D1\",\"Cat.3-D2\",\"QMont1\",\"QMont2\",\"QMont3\",\"QPall3\",\"RAija1\",\"RAija2\",\"RAija3\",\"RAija4\",\"RCota1\",\"RCota2\",\"RCota3\",\"RHuar1\",\"RHuar3\",\"RMall1\",\"RMalv1\",\"RMalv2\",\"Datos Resaltados\"],\n",
        "            \"eca2.3\":[\"Parametro\",\"Unidades\",\"Cat.3-D1\",\"Cat.3-D2\",\"QMont1\",\"QMont2\",\"QMont3\",\"QPall3\",\"RAija1\",\"RAija2\",\"RAija3\",\"RAija4\",\"RCota1\",\"RCota2\",\"RCota3\",\"RHuar1\",\"RHuar3\",\"RMall1\",\"RMalv1\",\"RMalv2\",\"Datos Resaltados\"]\n",
        "            },\n",
        "        }}\n",
        "]\n",
        "for archivo in archivosDict:\n",
        "  exceltemp=pd.ExcelFile(archivo[\"ruta\"])\n",
        "  for i in exceltemp.sheet_names:\n",
        "    skiprowtemp=archivo[\"especificaciones\"][\"hojas\"][str(i)][\"skiprows\"]\n",
        "    usecolstemp=archivo[\"especificaciones\"][\"hojas\"][str(i)][\"inicio\"]\n",
        "    categoriatemp=archivo[\"especificaciones\"][\"hojas\"][str(i)][\"categoría\"]\n",
        "    dftemp = pd.read_excel(archivo[\"ruta\"], sheet_name=i,skiprows=skiprowtemp,usecols=usecolstemp, header=None)\n",
        "    dftemp.columns = archivo[\"especificaciones\"][\"nuevosTitulos\"][str(i)]\n",
        "    dftemp=dftemp.transpose()\n",
        "    # Detecta filas y columnas vacías\n",
        "    if categoriatemp==1:\n",
        "      categoria1.append(dftemp)\n",
        "      print(f'posición {contador1} en el array de categoria1 ---> {archivo[\"ruta\"]}, hoja: {i}')\n",
        "      contador1+=1\n",
        "    elif categoriatemp==2:\n",
        "      categoria2.append(dftemp)\n",
        "      print(f'posición {contador2} en el array de categoria2 ---> {archivo[\"ruta\"]}, hoja: {i}')\n",
        "      contador2+=1\n",
        "    else:\n",
        "      categoria3.append(dftemp)\n",
        "      print(f'posición {contador3} en el array de categoria3 ---> {archivo[\"ruta\"]}, hoja: {i}')\n",
        "      contador3+=1\n"
      ],
      "metadata": {
        "id": "MWjX9uRDtufq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aqui tratamiento para cada tabla para poder obtener correctamente los datos... aquí me quedé\n",
        "for dftemp in categoria1:\n",
        "  display(dftemp)\n"
      ],
      "metadata": {
        "id": "ISNKOyTnv68M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM (Support Vector Machine)"
      ],
      "metadata": {
        "id": "Z8TusBZ-dAr7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LHTJCLVA0CDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "urDYwqEq0Aja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# aca le chambeo yo"
      ],
      "metadata": {
        "id": "ZseW0sjUdFKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###RANDOM FOREST"
      ],
      "metadata": {
        "id": "fApOUPvJz5nK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo entrenado con el conjunto de datos sin escalar\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "X=[[0.5384615384615384, 0.34615384615384615, 71.50487223318459], [0.5384615384615384, 0.1958041958041958, 97.5080952054009], [0.07692307692307693, 0.019230769230769232, 10.318913190095385]]\n",
        "y=['Regular', 'Malo', 'Excelente']\n",
        "# Codificar las etiquetas de texto a valores numéricos\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Entrenar el clasificador RandomForest\n",
        "clf_rnd = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "clf_rnd.fit(X, y)\n",
        "\n",
        "Z = clf_rnd.predict([X[0]])\n",
        "print(Z)\n",
        "\n"
      ],
      "metadata": {
        "id": "-92IvN960EJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = clf_rnd.predict(X)\n",
        "print(y_train_pred)"
      ],
      "metadata": {
        "id": "nkR7Xq862Hb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"F1 Score Train Set:\", f1_score(y_train_pred, y, average='weighted'))"
      ],
      "metadata": {
        "id": "ZiRsuT5K2JFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 3\n",
        "n_estimators = 30\n",
        "cmap = plt.cm.RdYlBu\n",
        "plot_step = 0.02  # fine step width for decision surface contours\n",
        "plot_step_coarser = 0.5  # step widths for coarse classifier guesses\n",
        "RANDOM_SEED = 13  # fix the seed on each iteration\n",
        "\n",
        "# Load data\n",
        "iris = load_iris()\n",
        "\n",
        "plot_idx = 1\n",
        "\n",
        "models = [\n",
        "    DecisionTreeClassifier(max_depth=None),\n",
        "    RandomForestClassifier(n_estimators=n_estimators),\n",
        "    ExtraTreesClassifier(n_estimators=n_estimators),\n",
        "    AdaBoostClassifier(\n",
        "        DecisionTreeClassifier(max_depth=3),\n",
        "        n_estimators=n_estimators,\n",
        "        algorithm=\"SAMME\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "for pair in ([0, 1], [0, 2], [2, 3]):\n",
        "    for model in models:\n",
        "        # We only take the two corresponding features\n",
        "        X = iris.data[:, pair]\n",
        "        y = iris.target\n",
        "\n",
        "        # Shuffle\n",
        "        idx = np.arange(X.shape[0])\n",
        "        np.random.seed(RANDOM_SEED)\n",
        "        np.random.shuffle(idx)\n",
        "        X = X[idx]\n",
        "        y = y[idx]\n",
        "\n",
        "        # Standardize\n",
        "        mean = X.mean(axis=0)\n",
        "        std = X.std(axis=0)\n",
        "        X = (X - mean) / std\n",
        "\n",
        "        # Train\n",
        "        model.fit(X, y)\n",
        "\n",
        "        scores = model.score(X, y)\n",
        "        # Create a title for each column and the console by using str() and\n",
        "        # slicing away useless parts of the string\n",
        "        model_title = str(type(model)).split(\".\")[-1][:-2][: -len(\"Classifier\")]\n",
        "\n",
        "        model_details = model_title\n",
        "        if hasattr(model, \"estimators_\"):\n",
        "            model_details += \" with {} estimators\".format(len(model.estimators_))\n",
        "        print(model_details + \" with features\", pair, \"has a score of\", scores)\n",
        "\n",
        "        plt.subplot(3, 4, plot_idx)\n",
        "        if plot_idx <= len(models):\n",
        "            # Add a title at the top of each column\n",
        "            plt.title(model_title, fontsize=9)\n",
        "\n",
        "        # Now plot the decision boundary using a fine mesh as input to a\n",
        "        # filled contour plot\n",
        "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "        xx, yy = np.meshgrid(\n",
        "            np.arange(x_min, x_max, plot_step), np.arange(y_min, y_max, plot_step)\n",
        "        )\n",
        "\n",
        "        # Plot either a single DecisionTreeClassifier or alpha blend the\n",
        "        # decision surfaces of the ensemble of classifiers\n",
        "        if isinstance(model, DecisionTreeClassifier):\n",
        "            Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "            Z = Z.reshape(xx.shape)\n",
        "            cs = plt.contourf(xx, yy, Z, cmap=cmap)\n",
        "        else:\n",
        "            # Choose alpha blend level with respect to the number\n",
        "            # of estimators\n",
        "            # that are in use (noting that AdaBoost can use fewer estimators\n",
        "            # than its maximum if it achieves a good enough fit early on)\n",
        "            estimator_alpha = 1.0 / len(model.estimators_)\n",
        "            for tree in model.estimators_:\n",
        "                Z = tree.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "                Z = Z.reshape(xx.shape)\n",
        "                cs = plt.contourf(xx, yy, Z, alpha=estimator_alpha, cmap=cmap)\n",
        "\n",
        "        # Build a coarser grid to plot a set of ensemble classifications\n",
        "        # to show how these are different to what we see in the decision\n",
        "        # surfaces. These points are regularly space and do not have a\n",
        "        # black outline\n",
        "        xx_coarser, yy_coarser = np.meshgrid(\n",
        "            np.arange(x_min, x_max, plot_step_coarser),\n",
        "            np.arange(y_min, y_max, plot_step_coarser),\n",
        "        )\n",
        "        Z_points_coarser = model.predict(\n",
        "            np.c_[xx_coarser.ravel(), yy_coarser.ravel()]\n",
        "        ).reshape(xx_coarser.shape)\n",
        "        cs_points = plt.scatter(\n",
        "            xx_coarser,\n",
        "            yy_coarser,\n",
        "            s=15,\n",
        "            c=Z_points_coarser,\n",
        "            cmap=cmap,\n",
        "            edgecolors=\"none\",\n",
        "        )\n",
        "\n",
        "        # Plot the training points, these are clustered together and have a\n",
        "        # black outline\n",
        "        plt.scatter(\n",
        "            X[:, 0],\n",
        "            X[:, 1],\n",
        "            c=y,\n",
        "            cmap=ListedColormap([\"r\", \"y\", \"b\"]),\n",
        "            edgecolor=\"k\",\n",
        "            s=20,\n",
        "        )\n",
        "        plot_idx += 1  # move on to the next plot in sequence\n",
        "\n",
        "plt.suptitle(\"Classifiers on feature subsets of the Iris dataset\", fontsize=12)\n",
        "plt.axis(\"tight\")\n",
        "plt.tight_layout(h_pad=0.2, w_pad=0.2, pad=2.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FCbl10YVe1GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Generación de datos"
      ],
      "metadata": {
        "id": "ANOMCt_9TNJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#https://www.kaggle.com/datasets/mssmartypants/water-quality\n",
        "df = pd.read_csv('./waterQuality1.csv')\n",
        "df = df[(df != 0).all(axis=1)]\n",
        "\n",
        "df['arsenic'] = df['arsenic']\n",
        "df['cadmium'] = df['cadmium']\n",
        "df['copper'] = df['copper'] *3\n",
        "df['chromium'] = df['chromium']*10\n",
        "df['lead'] = df['lead']*2\n",
        "df['mercury'] = df['mercury'] *100\n",
        "\n",
        "df.head()\n",
        "df_subset = df.head(400)\n",
        "\n",
        "# Reiniciar el índice del DataFrame seleccionado\n",
        "df_sample = df_subset.reset_index(drop=True)\n",
        "df_sample.drop('radium', axis=1, inplace=True)\n",
        "df_sample.drop('is_safe', axis=1, inplace=True)\n",
        "df_sample.drop('uranium', axis=1, inplace=True)\n",
        "df_sample.drop('silver', axis=1, inplace=True)\n",
        "df_sample.drop('selenium', axis=1, inplace=True)\n",
        "df_sample.drop('perchlorate', axis=1, inplace=True)\n",
        "df_sample.drop('flouride', axis=1, inplace=True)\n",
        "df_sample.drop('nitrites', axis=1, inplace=True)\n",
        "df_sample.drop('bacteria', axis=1, inplace=True)\n",
        "df_sample.drop('viruses', axis=1, inplace=True)\n",
        "df_sample.drop('nitrates', axis=1, inplace=True)\n",
        "df_sample.drop('ammonia', axis=1, inplace=True)\n",
        "df_sample.drop('chloramine', axis=1, inplace=True)\n",
        "df_sample = df_sample.rename(columns={'aluminium': 'al'})\n",
        "df_sample = df_sample.rename(columns={'arsenic': 'as'})\n",
        "df_sample = df_sample.rename(columns={'barium': 'b'})\n",
        "df_sample = df_sample.rename(columns={'cadmium': 'cd'})\n",
        "df_sample = df_sample.rename(columns={'chromium': 'cr'})\n",
        "df_sample = df_sample.rename(columns={'copper': 'cu'})\n",
        "df_sample = df_sample.rename(columns={'lead': 'pb'})\n",
        "df_sample = df_sample.rename(columns={'mercury': 'hg'})\n",
        "df_sample.info()\n"
      ],
      "metadata": {
        "id": "QtcwHBtS2icO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./water_potability.csv')\n",
        "df = df[(df != 0).all(axis=1)]\n",
        "\n",
        "# Tomar los primeros 2000 datos\n",
        "df_subset = df.head(400)\n",
        "\n",
        "# Reiniciar el índice del DataFrame seleccionado\n",
        "df = df_subset.reset_index(drop=True)\n",
        "df.drop('Hardness', axis=1, inplace=True)\n",
        "df.drop('Solids', axis=1, inplace=True)\n",
        "df.drop('Chloramines', axis=1, inplace=True)\n",
        "df.drop('Sulfate', axis=1, inplace=True)\n",
        "df.drop('Organic_carbon', axis=1, inplace=True)\n",
        "df.drop('Turbidity', axis=1, inplace=True)\n",
        "df.drop('Trihalomethanes', axis=1, inplace=True)\n",
        "df.drop('Potability', axis=1, inplace=True)\n",
        "df = df.rename(columns={'Conductivity': 'conductividad'})\n",
        "\n",
        "df_concat = pd.concat([df, df_sample], axis=1)\n",
        "\n",
        "df_concat.head()\n",
        "# df_concat.to_excel('data_incompleta.xlsx', index=False)"
      ],
      "metadata": {
        "id": "sVz7Rw75TBYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concat.info()"
      ],
      "metadata": {
        "id": "946DRjIWXQu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnas=[\"al\",\"as\",\"b\",\"cd\",\"cr\",\"cu\",\"dbo\",\"fe\",\"hg\",\"mn\",\"o\",\"pb\",\"zn\",\"ph\",\"conductividad\",\"coliformes\"]\n",
        "import numpy as np\n",
        "for columna in columnas:\n",
        "  if columna in df_concat.columns:\n",
        "      df_concat[columna] = df_concat[columna].fillna(df_concat[columna].max())\n",
        "    # df['Sulfate'] = df['Sulfate'].fillna(df['Sulfate'].median())\n",
        "    # df['Trihalomethanes'] = df['Trihalomethanes'].fillna(df['Trihalomethanes'].median())\n",
        "columnasNoHay=['dbo', 'fe', 'mn', 'o', 'zn', 'coliformes']\n",
        "rangos=[[.01,10],[.001,5],[.01,10],[0.2,20],[00.1,10],[500,3000]]\n",
        "for columna,rango in zip(columnasNoHay,rangos):\n",
        "  df_concat[columna] = np.random.uniform(rango[0], rango[1], len(df_concat))\n",
        "\n",
        "df_concat.info()"
      ],
      "metadata": {
        "id": "_896egIhXkLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concat_ordenado=df_concat[columnas]\n",
        "df_mini=df_concat_ordenado.head(19)\n",
        "\n",
        "\n",
        "#https://www.kaggle.com/code/paviah/water-quality-prediction-mohpo-with-xgbclassifier\n",
        "import io\n",
        "\n",
        "display(df_mini)\n"
      ],
      "metadata": {
        "id": "PgQlVb5-XmqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def guardar_df_en_hojas_aleatorias(df, nombre_archivo):\n",
        "    # Contador para las hojas\n",
        "    hoja_num = 1\n",
        "    with pd.ExcelWriter(nombre_archivo) as writer:\n",
        "      # while not df.empty:\n",
        "      #     # Elegir aleatoriamente el número de filas para la siguiente hoja (entre 4 y 12)\n",
        "      #     num_filas = np.random.randint(4, 13)\n",
        "\n",
        "      #     # Seleccionar las primeras 'num_filas' filas del DataFrame\n",
        "      #     df_hoja = df.iloc[:num_filas]\n",
        "\n",
        "      #     # Guardar esas filas en una hoja nueva\n",
        "      #     # df_hoja.to_excel(writer, sheet_name=f'Hoja{hoja_num}', index=False)\n",
        "          df.to_excel(writer, sheet_name=f'Hoja1', index=False)\n",
        "\n",
        "          # # Eliminar esas filas del DataFrame original\n",
        "          # df = df.iloc[num_filas:]\n",
        "\n",
        "          # # Incrementar el contador de hojas\n",
        "          # hoja_num += 1\n",
        "contains_nan = df_concat.isna().values.any()\n",
        "\n",
        "print(\"¿Contiene NaN?\", contains_nan)\n",
        "df_concat.to_csv('archivo_aleatorio.csv', index=False)\n",
        "guardar_df_en_hojas_aleatorias(df_concat, 'archivo_aleatorio.xlsx')"
      ],
      "metadata": {
        "id": "8foUABJ00-g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concat.iloc[1009:1013]"
      ],
      "metadata": {
        "id": "Fmz0lOUpuWQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(df_concat[\"hg\"].max())\n",
        "(df_concat[\"cu\"].max())\n",
        "(df_concat[\"as\"].max())\n",
        "(df_concat[\"cd\"].max())"
      ],
      "metadata": {
        "id": "PEKC6o8Iwh2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exagerados para pesimo\n"
      ],
      "metadata": {
        "id": "rz03Eu5l92UD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#https://www.kaggle.com/datasets/mssmartypants/water-quality\n",
        "df = pd.read_csv('./waterQuality1.csv')\n",
        "df = df[(df != 0).all(axis=1)]\n",
        "\n",
        "df['arsenic'] = df['arsenic']*1000\n",
        "df['cadmium'] = df['cadmium']*1000\n",
        "df['copper'] = df['copper'] *1000\n",
        "df['chromium'] = df['chromium']*1000\n",
        "df['lead'] = df['lead']*1000\n",
        "df['mercury'] = df['mercury'] *1000\n",
        "\n",
        "df.head()\n",
        "df_subset = df.head(4000)\n",
        "\n",
        "# Reiniciar el índice del DataFrame seleccionado\n",
        "df_sample = df_subset.reset_index(drop=True)\n",
        "df_sample.drop('radium', axis=1, inplace=True)\n",
        "df_sample.drop('is_safe', axis=1, inplace=True)\n",
        "df_sample.drop('uranium', axis=1, inplace=True)\n",
        "df_sample.drop('silver', axis=1, inplace=True)\n",
        "df_sample.drop('selenium', axis=1, inplace=True)\n",
        "df_sample.drop('perchlorate', axis=1, inplace=True)\n",
        "df_sample.drop('flouride', axis=1, inplace=True)\n",
        "df_sample.drop('nitrites', axis=1, inplace=True)\n",
        "df_sample.drop('bacteria', axis=1, inplace=True)\n",
        "df_sample.drop('viruses', axis=1, inplace=True)\n",
        "df_sample.drop('nitrates', axis=1, inplace=True)\n",
        "df_sample.drop('ammonia', axis=1, inplace=True)\n",
        "df_sample.drop('chloramine', axis=1, inplace=True)\n",
        "df_sample = df_sample.rename(columns={'aluminium': 'al'})\n",
        "df_sample = df_sample.rename(columns={'arsenic': 'as'})\n",
        "df_sample = df_sample.rename(columns={'barium': 'b'})\n",
        "df_sample = df_sample.rename(columns={'cadmium': 'cd'})\n",
        "df_sample = df_sample.rename(columns={'chromium': 'cr'})\n",
        "df_sample = df_sample.rename(columns={'copper': 'cu'})\n",
        "df_sample = df_sample.rename(columns={'lead': 'pb'})\n",
        "df_sample = df_sample.rename(columns={'mercury': 'hg'})\n",
        "df_sample.info()\n"
      ],
      "metadata": {
        "id": "7CUuRYah9tj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./water_potability.csv')\n",
        "df = df[(df != 0).all(axis=1)]\n",
        "\n",
        "# Tomar los primeros 2000 datos\n",
        "df_filtrado = df[(df['ph'] < 5.5) | (df['ph'] > 9)]\n",
        "\n",
        "df_subset = df_filtrado.head(4000)\n",
        "\n",
        "# Reiniciar el índice del DataFrame seleccionado\n",
        "df = df_subset.reset_index(drop=True)\n",
        "df.drop('Hardness', axis=1, inplace=True)\n",
        "df.drop('Solids', axis=1, inplace=True)\n",
        "df.drop('Chloramines', axis=1, inplace=True)\n",
        "df.drop('Sulfate', axis=1, inplace=True)\n",
        "df.drop('Organic_carbon', axis=1, inplace=True)\n",
        "df.drop('Turbidity', axis=1, inplace=True)\n",
        "df.drop('Trihalomethanes', axis=1, inplace=True)\n",
        "df.drop('Potability', axis=1, inplace=True)\n",
        "df = df.rename(columns={'Conductivity': 'conductividad'})\n",
        "\n",
        "df_concat = pd.concat([df, df_sample], axis=1)\n",
        "\n",
        "df_concat.head()\n",
        "# df_concat.to_excel('data_incompleta.xlsx', index=False)"
      ],
      "metadata": {
        "id": "aiK5G9V-_Bg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnas=[\"al\",\"as\",\"b\",\"cd\",\"cr\",\"cu\",\"dbo\",\"fe\",\"hg\",\"mn\",\"o\",\"pb\",\"zn\",\"ph\",\"conductividad\",\"coliformes\"]\n",
        "import numpy as np\n",
        "for columna in columnas:\n",
        "  if columna in df_concat.columns:\n",
        "      df_concat[columna] = df_concat[columna].fillna(df_concat[columna].max())\n",
        "    # df['Sulfate'] = df['Sulfate'].fillna(df['Sulfate'].median())\n",
        "    # df['Trihalomethanes'] = df['Trihalomethanes'].fillna(df['Trihalomethanes'].median())\n",
        "columnasNoHay=['dbo', 'fe', 'mn', 'o', 'zn', 'coliformes']\n",
        "rangos=[[1,1000],[1,1000],[1,1000],[1,1000],[1,100],[2000,100000]]\n",
        "for columna,rango in zip(columnasNoHay,rangos):\n",
        "  df_concat[columna] = np.random.uniform(rango[0], rango[1], len(df_concat))\n",
        "\n",
        "df_concat.info()"
      ],
      "metadata": {
        "id": "7o4vG3r4_HD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concat_ordenado=df_concat[columnas]\n",
        "df_mini=df_concat_ordenado.head(19)\n",
        "\n",
        "\n",
        "#https://www.kaggle.com/code/paviah/water-quality-prediction-mohpo-with-xgbclassifier\n",
        "import io\n",
        "\n",
        "display(df_mini)\n"
      ],
      "metadata": {
        "id": "RNoiRuuR_KsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def guardar_df_en_hojas_aleatorias(df, nombre_archivo):\n",
        "    # Contador para las hojas\n",
        "    hoja_num = 1\n",
        "    with pd.ExcelWriter(nombre_archivo) as writer:\n",
        "      # while not df.empty:\n",
        "      #     # Elegir aleatoriamente el número de filas para la siguiente hoja (entre 4 y 12)\n",
        "      #     num_filas = np.random.randint(4, 13)\n",
        "\n",
        "      #     # Seleccionar las primeras 'num_filas' filas del DataFrame\n",
        "      #     df_hoja = df.iloc[:num_filas]\n",
        "\n",
        "      #     # Guardar esas filas en una hoja nueva\n",
        "      #     # df_hoja.to_excel(writer, sheet_name=f'Hoja{hoja_num}', index=False)\n",
        "          df.to_excel(writer, sheet_name=f'Hoja1', index=False)\n",
        "\n",
        "          # # Eliminar esas filas del DataFrame original\n",
        "          # df = df.iloc[num_filas:]\n",
        "\n",
        "          # # Incrementar el contador de hojas\n",
        "          # hoja_num += 1\n",
        "contains_nan = df_concat.isna().values.any()\n",
        "\n",
        "print(\"¿Contiene NaN?\", contains_nan)\n",
        "guardar_df_en_hojas_aleatorias(df_concat, 'archivo_aleatorio_muy_exageraado.xlsx')"
      ],
      "metadata": {
        "id": "7frEKZEl_q7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concat.iloc[1009:1013]"
      ],
      "metadata": {
        "id": "KXpyt8v1_xQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(df_concat[\"hg\"].max())\n",
        "(df_concat[\"cu\"].max())\n",
        "(df_concat[\"as\"].max())\n",
        "(df_concat[\"cd\"].max())"
      ],
      "metadata": {
        "id": "ApNA-Y9a_11q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@classmethod\n",
        "def read_doc(cls, carpeta : str = './template' ) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Lee datos de un archivo de Excel ubicado en una carpeta específica.\n",
        "\n",
        "    Define la ruta del archivo de Excel y, si el archivo existe, lo lee utilizando `pd.read_excel`\n",
        "    y devuelve el contenido como un DataFrame. Si el archivo no se encuentra, imprime un mensaje de error.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Los datos del archivo de Excel leídos como un DataFrame.\n",
        "\n",
        "    Prints:\n",
        "        str: Mensaje de error si el archivo no se encuentra en la carpeta.\n",
        "    \"\"\"\n",
        "\n",
        "    #Se define el dorectorio para guardar el template\n",
        "    folder_path = f'/content/{carpeta}'\n",
        "\n",
        "    if not os.path.exists(carpeta):\n",
        "      os.makedirs(f'{carpeta}')\n",
        "      print(f\"Directorio '{f'{carpeta}'}' creado.\")\n",
        "      print(f'sube tus archivo de entrenamiento a la carpeta {carpeta}')\n",
        "      return  pd.DataFrame()\n",
        "    archivosEncarpeta = [\n",
        "      os.path.join(os.getcwd(), f'{carpeta}', x)\n",
        "      for x in os.listdir(f'{carpeta}')\n",
        "      if not x.startswith(\".ipynb_checkpoints\")  # Filtrar el archivo .ipynb_checkpoints\n",
        "      ] # genera todas las rutas de los xslx para leerlos\n",
        "    # print(f'La carpeta POS contiene : {str(len(categoria1paths))} archivos')\n",
        "    if len(archivosEncarpeta) ==0:\n",
        "      print(f\"Capeta {carpeta} vacía sube tu excel\")\n",
        "      return  pd.DataFrame()\n",
        "    #Intenta leer el archivo\n",
        "    full_path = os.path.join(folder_path, archivosEncarpeta[0])\n",
        "    if os.path.exists(full_path):\n",
        "        data = pd.read_excel(full_path, engine='openpyxl')\n",
        "        return data\n",
        "\n",
        "    print(f'No se ha encontrado el archivo en la carpeta {carpeta}')\n",
        "    return  pd.DataFrame()\n"
      ],
      "metadata": {
        "id": "QdPynuMMzCYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wLZlOG3pOUt2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}